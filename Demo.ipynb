{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from recsys.wide_deep import WideDeep\n",
    "from recsys.linucb import LinUCB\n",
    "from recsys.collaborative_deep_learning import DeepCollab\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input\n",
    "For recommendations for an existing user, select a user id between 6 and 53424.\n",
    "For recommendations for a new user, select a user id between 1 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 6 # REPLACE WITH DESIRED VALUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Demo:\n",
    "    def __init__(self, user_id):\n",
    "        self.user_id = user_id\n",
    "\n",
    "        self.cf = pickle.load(open('models/svd_model.pkl', 'rb'))\n",
    "        self.logistic = pickle.load(open('models/logreg_20170212.pkl', 'rb'))\n",
    "        self.linucb = pickle.load(open('models/linucb_alpha05_binary.pkl', 'rb'))\n",
    "        self.cdae = load_model('models/cdae_binary.h5')\n",
    "        self.widedeep = load_model('models/wide_deep_1_01_128_False.h5')\n",
    "\n",
    "        self.user_features = None\n",
    "        self.train_ratings = None\n",
    "        self.test_ratings = None\n",
    "        self.cold_ratings = None\n",
    "        self.train_pivot = None\n",
    "        self.full_ratings = None\n",
    "        self.content_features = None\n",
    "        self.books = None\n",
    "        self.user_book_info = None\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        self.full_ratings = pd.read_csv('data/unprocessed/ratings.csv')\n",
    "        self.user_features = pd.read_csv('data/user_features_final.csv', header=0)\n",
    "        self.content_features = pd.read_csv('data/books_with_latent_features.csv', header=0)\n",
    "        self.books = pd.read_csv('data/unprocessed/books.csv')\n",
    "        \n",
    "\n",
    "        if self.user_id > 5:\n",
    "            self.train_ratings = pd.read_csv('data/train_ratings_set.csv')\n",
    "            self.train_pivot = self.train_ratings.pivot(index='user_id', columns='book_id')\n",
    "            self.test_ratings = pd.read_csv('data/test_ratings_set.csv')\n",
    "            self.user_features['avg_rating'] /= 5\n",
    "\n",
    "            self.user_features = self.user_features[self.train_ratings['user_id'] == self.user_id]\n",
    "            print('User Features')\n",
    "            print(self.user_features)\n",
    "            print('\\n')\n",
    "            \n",
    "\n",
    "            self.train_ratings = self.train_ratings[self.train_ratings['user_id'] == self.user_id]\n",
    "            books = self.train_ratings.merge(self.books, on='book_id')\n",
    "            print('Historic Rating Data')\n",
    "            print(books[['title', 'authors', 'rating']])\n",
    "            print('\\n')\n",
    "\n",
    "            user_and_content = self.user_features.join(self.content_features.drop('book_id', axis=1), how='right', lsuffix='x')\n",
    "            user_ratings = self.train_pivot.loc[self.user_id]\n",
    "\n",
    "            all_books = self.test_ratings[self.test_ratings['user_id'] == self.user_id]['book_id'].tolist()\n",
    "            idx = [b - 1 for b in all_books]\n",
    "            filter_books = self.test_ratings[self.test_ratings['user_id'] == self.user_id]\n",
    "            test_book_ratings = filter_books[filter_books['book_id'].isin(all_books)]['rating'].tolist()\n",
    "            self.user_book_info = self.books[self.books['book_id'].isin(all_books)][['book_id', 'title', 'authors']]\n",
    "\n",
    "            self.predict_cf(user_ratings, idx, all_books, test_book_ratings, self.user_id)\n",
    "            self.predict_lr(user_and_content, idx, all_books, test_book_ratings)\n",
    "            self.predict_linucb(idx, all_books, test_book_ratings)\n",
    "            self.predict_cdae(user_ratings, idx, all_books, test_book_ratings)\n",
    "            self.predict_wd(user_and_content, idx, all_books, test_book_ratings)\n",
    "\n",
    "        else:\n",
    "            self.cold_ratings = pd.read_csv('data/cold_start_ratings_set.csv')\n",
    "\n",
    "            print('Cold Start User Selected')\n",
    "\n",
    "            all_books = self.cold_ratings[self.cold_ratings['user_id'] == self.user_id]['book_id'].tolist()\n",
    "            idx = [b - 1 for b in all_books]\n",
    "            filter_books = self.cold_ratings[self.cold_ratings['user_id'] == self.user_id]\n",
    "            test_book_ratings = filter_books[filter_books['book_id'].isin(all_books)]['rating'].tolist()\n",
    "            self.user_book_info = self.books[self.books['book_id'].isin(all_books)][['book_id', 'title', 'authors']]\n",
    "\n",
    "            self.user_features = self.user_features.drop('user_id', axis=1).mean()\n",
    "            self.user_features['average_rating'] /= 5\n",
    "\n",
    "            user_and_content = self.user_features.join(self.content_features.drop('book_id', axis=1), how='right')\n",
    "            user_ratings = np.zeros((1, 10000))\n",
    "\n",
    "            print('Collaborative filtering cannot predict cold start users. Proceeding to logistic regression.')\n",
    "\n",
    "            #self.predict_lr(user_and_content, idx, all_books, test_book_ratings)\n",
    "            self.predict_linucb(idx, all_books, test_book_ratings)\n",
    "            self.predict_cdae(user_ratings, idx, all_books, test_book_ratings)\n",
    "            self.predict_wd(user_and_content, idx, all_books, test_book_ratings)\n",
    "\n",
    "    def predict_cf(self, user_ratings, idx, all_books, test_book_ratings, user_id):\n",
    "        input_data = [(user_id, book_id, rating) for (book_id, rating) in zip(all_books, test_book_ratings)]\n",
    "        cf_predictions = self.cf.test(input_data)\n",
    "        pred_list = [[uid, iid, true_r, est] for uid, iid, true_r, est, _ in cf_predictions]\n",
    "        df = pd.DataFrame(pred_list, columns=['user_id', 'book_id', 'rating', 'pred'])\n",
    "        df['pred_proba'] = df['pred'].apply(lambda x: x / 5)\n",
    "        df['pred'] = df['pred'].apply(lambda x: round(x))\n",
    "        df['binary_rating'] = df.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "        df = df.sort_values(by='pred_proba')\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        top_recs = min(len(df), 10)\n",
    "        df = df[:top_recs]\n",
    "        df = df.merge(self.user_book_info, on='book_id')\n",
    "        df = df[['user_id', 'book_id', 'title', 'authors', 'rating', 'binary_rating', 'pred_proba', 'pred']]\n",
    "\n",
    "        print('SVD Collaboration Filtering Recommendations')\n",
    "        print(df)\n",
    "        print('\\n')\n",
    "\n",
    "    def predict_lr(self, user_and_content, idx, all_books, test_book_ratings):\n",
    "        lr_predictions = self.logistic.predict(np.asarray(user_and_content.drop('user_id', axis=1)))\n",
    "\n",
    "        raw_predictions = lr_predictions[idx].reshape(1, -1)[0]\n",
    "\n",
    "        df = pd.DataFrame({'book_id': all_books,\n",
    "                           'rating': test_book_ratings,\n",
    "                           'pred_proba': raw_predictions})\n",
    "\n",
    "        df['user_id'] = self.user_id\n",
    "\n",
    "        df['binary_rating'] = df.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "\n",
    "        min_p = df['pred_proba'].min()\n",
    "        max_p = df['pred_proba'].max()\n",
    "\n",
    "        df['prediction'] = df.apply(lambda x: self.scale_prediction_binary(x['pred_proba'], min_p, max_p), axis=1)\n",
    "        df = df.sort_values(by='pred_proba')\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        top_recs = min(len(df), 10)\n",
    "        df = df[:top_recs]\n",
    "        df = df.merge(self.user_book_info, on='book_id')\n",
    "        df = df[['user_id', 'book_id', 'title', 'authors', 'rating', 'binary_rating', 'pred_proba', 'prediction']]\n",
    "\n",
    "        print('Logistic Regression Recommendations')\n",
    "        print(df)\n",
    "        print('\\n')\n",
    "\n",
    "    def predict_linucb(self, idx, all_books, test_book_ratings):\n",
    "        mab_predictions = self.linucb.predict_proba(self.user_features)\n",
    "\n",
    "        df = pd.DataFrame({'book_id': list(mab_predictions[0].keys()),\n",
    "                           'pred_proba': list(mab_predictions[0].values())})\n",
    "\n",
    "        df['book_id'] = df.apply(lambda x: int(x['book_id']), axis=1)\n",
    "        evaluate = pd.DataFrame({'book_id': all_books, 'rating': test_book_ratings})\n",
    "\n",
    "        df = evaluate.merge(df, on='book_id')\n",
    "        df['user_id'] = int(self.user_id)\n",
    "\n",
    "        df['binary_rating'] = df.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "\n",
    "        min_p = df['pred_proba'].min()\n",
    "        max_p = df['pred_proba'].max()\n",
    "\n",
    "        df['prediction'] = df.apply(lambda x: self.scale_prediction_binary(x['pred_proba'], min_p, max_p), axis=1)\n",
    "        df = df.sort_values(by='pred_proba')\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        top_recs = min(len(df), 10)\n",
    "        df = df[:top_recs]\n",
    "        df = df.merge(self.user_book_info, on='book_id')\n",
    "        df = df[['user_id', 'book_id', 'title', 'authors', 'rating', 'binary_rating', 'pred_proba', 'prediction']]\n",
    "\n",
    "        print('LinUCB Recommendations')\n",
    "        print(df)\n",
    "        print('\\n')\n",
    "\n",
    "    def predict_cdae(self, user_ratings, idx, all_books, test_book_ratings):\n",
    "        cdae_predictions = self.cdae.predict([[user_ratings],\n",
    "                                                  np.asarray(self.user_features.drop('user_id', axis=1))])\n",
    "\n",
    "        raw_predictions = cdae_predictions[:,idx]\n",
    "\n",
    "        df = pd.DataFrame({'book_id': all_books,\n",
    "                           'rating': test_book_ratings,\n",
    "                           'pred_proba': raw_predictions[0]})\n",
    "\n",
    "        df['user_id'] = self.user_id\n",
    "\n",
    "        df['binary_rating'] = df.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "\n",
    "        min_p = df['pred_proba'].min()\n",
    "        max_p = df['pred_proba'].max()\n",
    "\n",
    "        df['prediction'] = df.apply(lambda x: self.scale_prediction_binary(x['pred_proba'], min_p, max_p), axis=1)\n",
    "        df = df.sort_values(by='pred_proba')\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        top_recs = min(len(df), 10)\n",
    "        df = df[:top_recs]\n",
    "        df = df.merge(self.user_book_info, on='book_id')\n",
    "        df = df[['user_id', 'book_id', 'title', 'authors', 'rating', 'binary_rating', 'pred_proba', 'prediction']]\n",
    "\n",
    "        print('Collaborative Denoising Autoencoder Recommendations')\n",
    "        print(df)\n",
    "        print('\\n')\n",
    "\n",
    "    def predict_wd(self, user_and_content, idx, all_books, test_book_ratings):\n",
    "        wd_predictions = self.widedeep.predict(np.asarray(user_and_content.drop('user_id', axis=1)))\n",
    "\n",
    "        raw_predictions = wd_predictions[idx].reshape(1, -1)[0]\n",
    "\n",
    "        df = pd.DataFrame({'book_id': all_books,\n",
    "                           'rating': test_book_ratings,\n",
    "                           'pred_proba': raw_predictions})\n",
    "\n",
    "        df['user_id'] = self.user_id\n",
    "\n",
    "        df['binary_rating'] = df.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "\n",
    "        min_p = df['pred_proba'].min()\n",
    "        max_p = df['pred_proba'].max()\n",
    "\n",
    "        df['prediction'] = df.apply(lambda x: self.scale_prediction_binary(x['pred_proba'], min_p, max_p), axis=1)\n",
    "        df = df.sort_values(by='pred_proba')\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        top_recs = min(len(df), 10)\n",
    "        df = df[:top_recs]\n",
    "        df = df.merge(self.user_book_info, on='book_id')\n",
    "        df = df[['user_id', 'book_id', 'title', 'authors', 'rating', 'binary_rating', 'pred_proba', 'prediction']]\n",
    "\n",
    "        print('Wide and Deep Recommendations')\n",
    "        print(df)\n",
    "        print('\\n')\n",
    "\n",
    "    @staticmethod\n",
    "    def scale_prediction_binary(x, min_p, max_p):\n",
    "            raw = (x - min_p) / (max_p - min_p)\n",
    "            return np.rint(raw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeWarning",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeWarning\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-37892ca7b87c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-3a07a770a699>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, user_id)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/svd_model.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/logreg_20170212.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinucb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/linucb_alpha05_binary.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/cdae_binary.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0m__check_build\u001b[0m  \u001b[0;31m# avoid flakes unused variable error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m from .validation import (as_float_array,\n\u001b[1;32m     12\u001b[0m                          \u001b[0massert_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m__init__.pxd\u001b[0m in \u001b[0;36minit sklearn.utils.murmurhash\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeWarning\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88"
     ]
    }
   ],
   "source": [
    "demo = Demo(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "demo.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
