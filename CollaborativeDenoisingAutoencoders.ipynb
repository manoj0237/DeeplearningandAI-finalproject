{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from recsys.collaborative_deep_learning import DeepCollab\n",
    "import recsys.evaluate as ev\n",
    "\n",
    "from keras.layers import Dense, Input, Concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_ratings = pd.read_csv('data/unprocessed/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_features = pd.read_csv('data/user_features_final.csv')\n",
    "users = user_features['user_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_users, test_users = train_test_split(users, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_users = pd.read_csv('data/train_ratings_set.csv')\n",
    "train_data_users = data_users[data_users['user_id'].isin(train_users)]\n",
    "test_data_users = data_users[data_users['user_id'].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_users.to_csv('data/backups/autoencoder_train.csv', index=False)\n",
    "test_data_users.to_csv('data/backups/autoencoder_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_users = pd.read_csv('data/backups/autoencoder_train.csv')\n",
    "train_data_users['rating'] = train_data_users.apply(lambda x: x['rating'] / 5, axis=1)\n",
    "\n",
    "train_data_users = train_data_users.pivot(index='user_id', columns='book_id')\n",
    "\n",
    "train_data_users.fillna(0, inplace=True)\n",
    "train_data_users = np.asarray(train_data_users)\n",
    "train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_binary_data_users = pd.read_csv('data/backups/autoencoder_train.csv')\n",
    "train_binary_data_users['rating'] = train_binary_data_users.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "train_binary_data_users = train_binary_data_users.pivot(index='user_id', columns='book_id')\n",
    "train_binary_data_users.fillna(0, inplace=True)\n",
    "train_binary_data_users = np.asarray(train_binary_data_users)\n",
    "train_binary_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voldemort/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('data/backups/autoencoder_train.csv')\n",
    "train_users = list(set(temp['user_id'].tolist()))\n",
    "denoised_train_data_users = full_ratings[full_ratings['user_id'].isin(train_users)]\n",
    "denoised_train_data_users['rating'] = denoised_train_data_users.apply(lambda x: x['rating'] / 5, axis=1)\n",
    "denoised_train_data_users = denoised_train_data_users.pivot(index='user_id', columns='book_id')\n",
    "denoised_train_data_users.fillna(0, inplace=True)\n",
    "denoised_train_data_users = np.asarray(denoised_train_data_users)\n",
    "denoised_train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voldemort/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised_train_binary_data_users = full_ratings[full_ratings['user_id'].isin(train_users)]\n",
    "denoised_train_binary_data_users['rating'] = denoised_train_binary_data_users.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "\n",
    "denoised_train_binary_data_users = denoised_train_binary_data_users.pivot(index='user_id', columns='book_id')\n",
    "denoised_train_binary_data_users.fillna(0, inplace=True)\n",
    "denoised_train_binary_data_users = np.asarray(denoised_train_binary_data_users)\n",
    "denoised_train_binary_data_users.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Denoising Autoencoder\n",
    "## 5 Star\n",
    "## Relu Activation\n",
    "Relu activation for final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 120,501,024\n",
      "Trainable params: 120,501,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 395us/step - loss: 3297.2810 - acc: 0.1651 - val_loss: 3221.1377 - val_acc: 0.1851\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 389us/step - loss: 3253.2290 - acc: 0.1486 - val_loss: 3201.7023 - val_acc: 0.1526\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 394us/step - loss: 3238.8027 - acc: 0.1363 - val_loss: 3194.3691 - val_acc: 0.1453\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 390us/step - loss: 3231.0492 - acc: 0.1368 - val_loss: 3194.7767 - val_acc: 0.1642\n"
     ]
    }
   ],
   "source": [
    "model = DeepCollab(batch_size=128, hidden_layers=1, user_features=False)\n",
    "model.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,551,136\n",
      "Trainable params: 121,551,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 396us/step - loss: 3349.3614 - acc: 0.1269 - val_loss: 3286.1279 - val_acc: 0.1880\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 395us/step - loss: 3308.9621 - acc: 0.1751 - val_loss: 3266.8313 - val_acc: 0.1933\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 389us/step - loss: 3291.7457 - acc: 0.1655 - val_loss: 3262.3881 - val_acc: 0.1920\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 391us/step - loss: 3286.7746 - acc: 0.1680 - val_loss: 3258.7773 - val_acc: 0.1883\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 391us/step - loss: 3281.8157 - acc: 0.1635 - val_loss: 3255.1993 - val_acc: 0.1844\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 391us/step - loss: 3277.9733 - acc: 0.1603 - val_loss: 3252.1937 - val_acc: 0.1829\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 3275.5323 - acc: 0.1573 - val_loss: 3252.1099 - val_acc: 0.1770\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 12s 389us/step - loss: 3272.9893 - acc: 0.1556 - val_loss: 3249.8914 - val_acc: 0.1772\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 3271.6201 - acc: 0.1573 - val_loss: 3249.0795 - val_acc: 0.1788\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 12s 394us/step - loss: 3268.4644 - acc: 0.1538 - val_loss: 3247.2613 - val_acc: 0.1760\n",
      "Epoch 11/100\n",
      "29914/29914 [==============================] - 12s 392us/step - loss: 3266.4041 - acc: 0.1535 - val_loss: 3244.5517 - val_acc: 0.1769\n",
      "Epoch 12/100\n",
      "29914/29914 [==============================] - 12s 391us/step - loss: 3263.7520 - acc: 0.1555 - val_loss: 3243.1799 - val_acc: 0.1734\n",
      "Epoch 13/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 3260.8866 - acc: 0.1515 - val_loss: 3240.1727 - val_acc: 0.1748\n",
      "Epoch 14/100\n",
      "29914/29914 [==============================] - 12s 396us/step - loss: 3259.3988 - acc: 0.1532 - val_loss: 3239.5943 - val_acc: 0.1726\n",
      "Epoch 15/100\n",
      "29914/29914 [==============================] - 12s 396us/step - loss: 3257.3164 - acc: 0.1489 - val_loss: 3238.8582 - val_acc: 0.1685\n",
      "Epoch 16/100\n",
      "29914/29914 [==============================] - 12s 389us/step - loss: 3256.3978 - acc: 0.1493 - val_loss: 3237.3699 - val_acc: 0.1719\n",
      "Epoch 17/100\n",
      "29914/29914 [==============================] - 12s 391us/step - loss: 3256.1819 - acc: 0.1496 - val_loss: 3237.0106 - val_acc: 0.1683\n",
      "Epoch 18/100\n",
      "29914/29914 [==============================] - 12s 392us/step - loss: 3252.5267 - acc: 0.1444 - val_loss: 3237.6189 - val_acc: 0.1706\n"
     ]
    }
   ],
   "source": [
    "model2 = DeepCollab(batch_size=128, hidden_layers=3, user_features=False)\n",
    "model2.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,814,048\n",
      "Trainable params: 121,814,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 400us/step - loss: 2670.3140 - acc: 0.0886 - val_loss: 2421.8886 - val_acc: 0.1285\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 394us/step - loss: 2449.9063 - acc: 0.1426 - val_loss: 2369.3697 - val_acc: 0.1670\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 397us/step - loss: 2406.6175 - acc: 0.1576 - val_loss: 2338.8738 - val_acc: 0.1780\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 2379.9273 - acc: 0.1568 - val_loss: 2330.2397 - val_acc: 0.1749\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 397us/step - loss: 2368.5003 - acc: 0.1564 - val_loss: 2329.4035 - val_acc: 0.1753\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 399us/step - loss: 2351.8230 - acc: 0.1582 - val_loss: 2314.7683 - val_acc: 0.1808\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 2342.7840 - acc: 0.1620 - val_loss: 2299.4517 - val_acc: 0.1781\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 12s 397us/step - loss: 2332.6955 - acc: 0.1602 - val_loss: 2301.6238 - val_acc: 0.1784\n"
     ]
    }
   ],
   "source": [
    "model3 = DeepCollab(batch_size=128, hidden_layers=5, user_features=False)\n",
    "model3.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.autoencoder.save('models/autoencoder_full_noise_5layers.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16026/16026 [==============================] - 3s 215us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model3.predict(test_data_users, test_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4881435. , 5282606.5, 2000445.1, ...,       0. ,       0. ,\n",
       "             0. ], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predictions explain the low accuracy. We should experiment with the activation function and scaling the ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu with Scaled Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 120,501,024\n",
      "Trainable params: 120,501,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 21s 696us/step - loss: 518.1352 - acc: 0.0973 - val_loss: 497.8379 - val_acc: 0.1199\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 21s 692us/step - loss: 499.9928 - acc: 0.1160 - val_loss: 490.3344 - val_acc: 0.1397\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 21s 693us/step - loss: 495.3423 - acc: 0.1182 - val_loss: 485.8253 - val_acc: 0.1399\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 21s 692us/step - loss: 491.8646 - acc: 0.1189 - val_loss: 483.0135 - val_acc: 0.1423\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 21s 691us/step - loss: 489.4367 - acc: 0.1219 - val_loss: 481.1499 - val_acc: 0.1408\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 21s 693us/step - loss: 487.1248 - acc: 0.1215 - val_loss: 480.0431 - val_acc: 0.1389\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 21s 693us/step - loss: 485.4256 - acc: 0.1215 - val_loss: 479.7052 - val_acc: 0.1494\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 21s 693us/step - loss: 483.9275 - acc: 0.1244 - val_loss: 477.9619 - val_acc: 0.1460\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 21s 693us/step - loss: 482.1275 - acc: 0.1255 - val_loss: 476.8718 - val_acc: 0.1471\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 21s 693us/step - loss: 480.8558 - acc: 0.1258 - val_loss: 478.2163 - val_acc: 0.1432\n"
     ]
    }
   ],
   "source": [
    "model = DeepCollab(batch_size=64, hidden_layers=1, user_features=False)\n",
    "model.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Activation\n",
    "Activation changed for final layer in DeelCollab class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_users = pd.read_csv('data/backups/autoencoder_train.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_users = list(set(train_data_users['user_id'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_users['rating'] = train_data_users.apply(lambda x: x['rating']/5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_users = train_data_users.pivot(index='user_id', columns='book_id')\n",
    "train_data_users.fillna(0, inplace=True)\n",
    "train_data_users = np.asarray(train_data_users)\n",
    "train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voldemort/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ratings = pd.read_csv('data/unprocessed/ratings.csv', header=0)\n",
    "denoised_train_data_users = full_ratings[full_ratings['user_id'].isin(train_users)].copy()\n",
    "\n",
    "denoised_train_data_users['rating'] = denoised_train_data_users.apply(lambda x: x['rating']/5, axis=1)\n",
    "denoised_train_data_users = denoised_train_data_users.pivot(index='user_id', columns='book_id')\n",
    "denoised_train_data_users.fillna(0, inplace=True)\n",
    "denoised_train_data_users = np.asarray(denoised_train_data_users)\n",
    "denoised_train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 120,501,024\n",
      "Trainable params: 120,501,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 453.8248 - acc: 0.0793 - val_loss: 420.2025 - val_acc: 0.0449\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 21s 690us/step - loss: 420.1549 - acc: 0.0348 - val_loss: 409.5415 - val_acc: 0.0238\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 21s 690us/step - loss: 406.1469 - acc: 0.0332 - val_loss: 403.3180 - val_acc: 0.0274\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 21s 692us/step - loss: 395.6390 - acc: 0.0288 - val_loss: 400.8324 - val_acc: 0.0227\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 21s 692us/step - loss: 387.4741 - acc: 0.0291 - val_loss: 400.5211 - val_acc: 0.0211\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 21s 693us/step - loss: 521.4398 - acc: 0.1159 - val_loss: 553.9970 - val_acc: 0.1619\n"
     ]
    }
   ],
   "source": [
    "model = DeepCollab(batch_size=64, hidden_layers=1, user_features=False)\n",
    "model.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 120,501,024\n",
      "Trainable params: 120,501,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/20\n",
      "29914/29914 [==============================] - 21s 694us/step - loss: 453.8025 - acc: 0.0785 - val_loss: 420.3859 - val_acc: 0.0317\n",
      "Epoch 2/20\n",
      "29914/29914 [==============================] - 21s 689us/step - loss: 419.9493 - acc: 0.0342 - val_loss: 409.2623 - val_acc: 0.0278\n",
      "Epoch 3/20\n",
      "29914/29914 [==============================] - 21s 692us/step - loss: 405.7761 - acc: 0.0314 - val_loss: 402.5862 - val_acc: 0.0337\n",
      "Epoch 4/20\n",
      "29914/29914 [==============================] - 21s 690us/step - loss: 395.1738 - acc: 0.0288 - val_loss: 400.8219 - val_acc: 0.0297\n",
      "Epoch 5/20\n",
      "29914/29914 [==============================] - 21s 691us/step - loss: 388.1862 - acc: 0.0282 - val_loss: 411.0636 - val_acc: 0.0254\n",
      "Epoch 6/20\n",
      "29914/29914 [==============================] - 21s 691us/step - loss: 492.2966 - acc: 0.0946 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 7/20\n",
      "29914/29914 [==============================] - 21s 691us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 8/20\n",
      "29914/29914 [==============================] - 21s 692us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 9/20\n",
      "29914/29914 [==============================] - 21s 692us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 10/20\n",
      "29914/29914 [==============================] - 21s 691us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 11/20\n",
      "29914/29914 [==============================] - 21s 692us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 12/20\n",
      "29914/29914 [==============================] - 21s 692us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 13/20\n",
      "29914/29914 [==============================] - 21s 690us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 14/20\n",
      "29914/29914 [==============================] - 21s 691us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 15/20\n",
      "29914/29914 [==============================] - 21s 691us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 16/20\n",
      "29914/29914 [==============================] - 21s 691us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 17/20\n",
      "29914/29914 [==============================] - 21s 691us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 18/20\n",
      "29914/29914 [==============================] - 21s 690us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 19/20\n",
      "29914/29914 [==============================] - 21s 691us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n",
      "Epoch 20/20\n",
      "29914/29914 [==============================] - 21s 692us/step - loss: 569.1827 - acc: 0.1455 - val_loss: 553.9970 - val_acc: 0.1619\n"
     ]
    }
   ],
   "source": [
    "model = DeepCollab(batch_size=64, hidden_layers=1, user_features=False, epochs=20, earlystopping=False)\n",
    "model.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voldemort/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_users = data_users[data_users['user_id'].isin(train_users)]\n",
    "\n",
    "train_data_users['rating'] = train_data_users.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "train_data_users = train_data_users.pivot(index='user_id', columns='book_id')\n",
    "train_data_users.fillna(0, inplace=True)\n",
    "train_data_users = np.asarray(train_data_users)\n",
    "train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voldemort/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised_train_data_users = full_ratings[full_ratings['user_id'].isin(train_users)]\n",
    "denoised_train_data_users['rating'] = denoised_train_data_users.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "denoised_train_data_users = denoised_train_data_users.pivot(index='user_id', columns='book_id')\n",
    "denoised_train_data_users.fillna(0, inplace=True)\n",
    "denoised_train_data_users = np.asarray(denoised_train_data_users)\n",
    "denoised_train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 120,501,024\n",
      "Trainable params: 120,501,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 390us/step - loss: 459.1833 - acc: 0.0682 - val_loss: 448.3762 - val_acc: 0.0558\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 389us/step - loss: 438.9374 - acc: 0.0933 - val_loss: 442.6482 - val_acc: 0.1056\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 385us/step - loss: 432.4222 - acc: 0.1097 - val_loss: 439.3085 - val_acc: 0.1141\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 385us/step - loss: 428.3214 - acc: 0.1181 - val_loss: 437.9451 - val_acc: 0.1225\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 386us/step - loss: 425.3154 - acc: 0.1238 - val_loss: 435.0158 - val_acc: 0.1231\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 388us/step - loss: 422.2267 - acc: 0.1240 - val_loss: 433.8437 - val_acc: 0.1317\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 12s 390us/step - loss: 419.8214 - acc: 0.1314 - val_loss: 432.3677 - val_acc: 0.1383\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 12s 391us/step - loss: 418.0358 - acc: 0.1345 - val_loss: 431.4048 - val_acc: 0.1392\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 12s 386us/step - loss: 416.6127 - acc: 0.1365 - val_loss: 430.9331 - val_acc: 0.1396\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 12s 387us/step - loss: 414.8229 - acc: 0.1384 - val_loss: 429.8576 - val_acc: 0.1400\n",
      "Epoch 11/100\n",
      "29914/29914 [==============================] - 12s 387us/step - loss: 413.4696 - acc: 0.1373 - val_loss: 429.8224 - val_acc: 0.1460\n",
      "Epoch 12/100\n",
      "29914/29914 [==============================] - 12s 390us/step - loss: 412.4587 - acc: 0.1370 - val_loss: 429.0801 - val_acc: 0.1364\n",
      "Epoch 13/100\n",
      "29914/29914 [==============================] - 12s 389us/step - loss: 411.4150 - acc: 0.1367 - val_loss: 429.1650 - val_acc: 0.1455\n"
     ]
    }
   ],
   "source": [
    "model = DeepCollab(batch_size=128, hidden_layers=1, user_features=False)\n",
    "model.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,551,136\n",
      "Trainable params: 121,551,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 394us/step - loss: 458.8051 - acc: 0.0893 - val_loss: 447.0984 - val_acc: 0.1431\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 394us/step - loss: 432.1111 - acc: 0.1280 - val_loss: 433.0866 - val_acc: 0.1693\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 390us/step - loss: 423.7155 - acc: 0.1460 - val_loss: 427.8222 - val_acc: 0.1770\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 390us/step - loss: 417.6842 - acc: 0.1581 - val_loss: 423.3665 - val_acc: 0.1872\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 414.1268 - acc: 0.1665 - val_loss: 420.8984 - val_acc: 0.1916\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 411.0579 - acc: 0.1772 - val_loss: 418.9889 - val_acc: 0.1897\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 408.8484 - acc: 0.1789 - val_loss: 417.8302 - val_acc: 0.1978\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 12s 392us/step - loss: 406.8904 - acc: 0.1820 - val_loss: 417.1323 - val_acc: 0.2028\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 405.0961 - acc: 0.1849 - val_loss: 415.6692 - val_acc: 0.1923\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 404.0779 - acc: 0.1846 - val_loss: 415.4371 - val_acc: 0.2095\n",
      "Epoch 11/100\n",
      "29914/29914 [==============================] - 12s 392us/step - loss: 403.3613 - acc: 0.1873 - val_loss: 414.6961 - val_acc: 0.2134\n",
      "Epoch 12/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 401.6810 - acc: 0.1873 - val_loss: 415.1192 - val_acc: 0.2103\n"
     ]
    }
   ],
   "source": [
    "model2 = DeepCollab(batch_size=128, hidden_layers=3, user_features=False)\n",
    "model2.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,814,048\n",
      "Trainable params: 121,814,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 401us/step - loss: 459.3127 - acc: 0.0290 - val_loss: 441.4307 - val_acc: 0.0540\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 432.9543 - acc: 0.1569 - val_loss: 434.6152 - val_acc: 0.2138\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 423.2152 - acc: 0.2183 - val_loss: 425.2357 - val_acc: 0.2551\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 399us/step - loss: 416.5870 - acc: 0.2199 - val_loss: 422.1041 - val_acc: 0.2475\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 400us/step - loss: 413.9770 - acc: 0.2219 - val_loss: 418.4160 - val_acc: 0.2535\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 410.2627 - acc: 0.2213 - val_loss: 415.5934 - val_acc: 0.2554\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 408.2783 - acc: 0.2273 - val_loss: 414.7526 - val_acc: 0.2437\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 12s 399us/step - loss: 406.9840 - acc: 0.2203 - val_loss: 415.5638 - val_acc: 0.2425\n"
     ]
    }
   ],
   "source": [
    "model3 = DeepCollab(batch_size=128, hidden_layers=5, user_features=False)\n",
    "model3.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.autoencoder.save('models/autoencoder_5layers_128batch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_users.dump('data/backups/autoencoder_train_binary.csv')\n",
    "denoised_train_data_users.dump('data/backups/autoencoder_train_denoised_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_users = np.load('data/backups/autoencoder_train_binary.csv')\n",
    "denoised_train_data_users = np.load('data/backups/autoencoder_train_denoised_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,814,048\n",
      "Trainable params: 121,814,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 21s 715us/step - loss: 457.7000 - acc: 0.1466 - val_loss: 443.7068 - val_acc: 0.2169\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 432.3066 - acc: 0.2094 - val_loss: 432.5758 - val_acc: 0.2321\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 425.5011 - acc: 0.2134 - val_loss: 428.4914 - val_acc: 0.2450\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 421.4314 - acc: 0.2158 - val_loss: 423.8077 - val_acc: 0.2388\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 21s 706us/step - loss: 418.4475 - acc: 0.2195 - val_loss: 421.9428 - val_acc: 0.2519\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 414.4617 - acc: 0.2206 - val_loss: 420.5861 - val_acc: 0.2491\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 21s 704us/step - loss: 411.4252 - acc: 0.2165 - val_loss: 416.1974 - val_acc: 0.2474\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 409.1624 - acc: 0.2136 - val_loss: 415.7889 - val_acc: 0.2432\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 21s 704us/step - loss: 407.2802 - acc: 0.2188 - val_loss: 413.7895 - val_acc: 0.2455\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 21s 705us/step - loss: 404.9904 - acc: 0.2152 - val_loss: 412.0845 - val_acc: 0.2444\n",
      "Epoch 11/100\n",
      "29914/29914 [==============================] - 21s 704us/step - loss: 403.5021 - acc: 0.2095 - val_loss: 411.7538 - val_acc: 0.2304\n",
      "Epoch 12/100\n",
      "29914/29914 [==============================] - 21s 704us/step - loss: 401.9401 - acc: 0.2068 - val_loss: 411.4620 - val_acc: 0.2320\n",
      "Epoch 13/100\n",
      "29914/29914 [==============================] - 21s 706us/step - loss: 400.7282 - acc: 0.2070 - val_loss: 410.2923 - val_acc: 0.2363\n",
      "Epoch 14/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 400.2936 - acc: 0.2049 - val_loss: 409.9349 - val_acc: 0.2261\n",
      "Epoch 15/100\n",
      "29914/29914 [==============================] - 21s 705us/step - loss: 399.1970 - acc: 0.2022 - val_loss: 409.4957 - val_acc: 0.2317\n",
      "Epoch 16/100\n",
      "29914/29914 [==============================] - 21s 700us/step - loss: 398.4281 - acc: 0.1996 - val_loss: 410.3933 - val_acc: 0.2296\n"
     ]
    }
   ],
   "source": [
    "model4 = DeepCollab(batch_size=64, hidden_layers=5, user_features=False)\n",
    "model4.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,814,048\n",
      "Trainable params: 121,814,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 8s 265us/step - loss: 467.2585 - acc: 0.0509 - val_loss: 445.6084 - val_acc: 0.1879\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 8s 261us/step - loss: 433.7063 - acc: 0.1770 - val_loss: 431.6677 - val_acc: 0.1982\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 8s 263us/step - loss: 423.4908 - acc: 0.1790 - val_loss: 423.5295 - val_acc: 0.2135\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 8s 262us/step - loss: 417.5744 - acc: 0.1995 - val_loss: 420.4651 - val_acc: 0.2272\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 8s 261us/step - loss: 413.1279 - acc: 0.2085 - val_loss: 417.1684 - val_acc: 0.2316\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 8s 261us/step - loss: 409.9814 - acc: 0.2071 - val_loss: 414.5389 - val_acc: 0.2385\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 8s 265us/step - loss: 407.4847 - acc: 0.2076 - val_loss: 413.4007 - val_acc: 0.2371\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 8s 261us/step - loss: 405.5616 - acc: 0.2098 - val_loss: 411.4926 - val_acc: 0.2389\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 7s 249us/step - loss: 403.6068 - acc: 0.2114 - val_loss: 410.8215 - val_acc: 0.2357\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 8s 260us/step - loss: 402.5377 - acc: 0.2088 - val_loss: 410.3382 - val_acc: 0.2321\n",
      "Epoch 11/100\n",
      "29914/29914 [==============================] - 8s 259us/step - loss: 401.0618 - acc: 0.2064 - val_loss: 410.4008 - val_acc: 0.2321\n"
     ]
    }
   ],
   "source": [
    "model4 = DeepCollab(batch_size=256, hidden_layers=5, user_features=False)\n",
    "model4.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Inputs (CDAE)\n",
    "## 5 Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.read_csv('data/backups/autoencoder_train.csv', header=0)\n",
    "train_users = list(set(temp['user_id'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_features = pd.read_csv('data/user_features_final.csv')\n",
    "train_user_features = user_features[user_features['user_id'].isin(list(train_users))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 27)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_user_features['avg_rating'] = train_user_features.apply(lambda x: x['avg_rating']/5, axis=1)\n",
    "train_user_features.drop('user_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_user_features = np.asarray(train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_users = train_data_users.pivot(index='user_id', columns='book_id')\n",
    "train_data_users.fillna(0, inplace=True)\n",
    "train_data_users = np.asarray(train_data_users)\n",
    "train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised_train_data_users = full_ratings[full_ratings['user_id'].isin(train_users)]\n",
    "denoised_train_data_users = denoised_train_data_users.pivot(index='user_id', columns='book_id')\n",
    "denoised_train_data_users.fillna(0, inplace=True)\n",
    "denoised_train_data_users = np.asarray(denoised_train_data_users)\n",
    "denoised_train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10000)        100010000   input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 26)           702         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10026)        0           dense_10[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         10267648    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 10000)        10250000    dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 120,528,350\n",
      "Trainable params: 120,528,350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 21s 702us/step - loss: 520.2776 - acc: 0.0963 - val_loss: 493.5159 - val_acc: 0.1066\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 21s 697us/step - loss: 499.7913 - acc: 0.1063 - val_loss: 491.0780 - val_acc: 0.1222\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 21s 697us/step - loss: 493.5079 - acc: 0.1153 - val_loss: 484.5418 - val_acc: 0.1185\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 21s 695us/step - loss: 490.6488 - acc: 0.1151 - val_loss: 481.5334 - val_acc: 0.1353\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 21s 698us/step - loss: 487.9606 - acc: 0.1233 - val_loss: 480.0202 - val_acc: 0.1361\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 21s 696us/step - loss: 485.5659 - acc: 0.1256 - val_loss: 478.9076 - val_acc: 0.1455\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 21s 698us/step - loss: 483.1034 - acc: 0.1260 - val_loss: 480.2967 - val_acc: 0.1488\n"
     ]
    }
   ],
   "source": [
    "model = DeepCollab(batch_size=64, hidden_layers=1, user_features=True)\n",
    "model.fit(train_data_users, denoised_train_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 10000)        100010000   input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 26)           702         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 10026)        0           dense_14[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1024)         10267648    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 512)          524800      dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1024)         525312      dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 10000)        10250000    dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 121,578,462\n",
      "Trainable params: 121,578,462\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 21s 708us/step - loss: 518.4261 - acc: 0.0773 - val_loss: 486.8885 - val_acc: 0.1326\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 21s 705us/step - loss: 491.3612 - acc: 0.1202 - val_loss: 478.1477 - val_acc: 0.1669\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 21s 706us/step - loss: 483.7856 - acc: 0.1410 - val_loss: 473.8878 - val_acc: 0.1768\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 21s 705us/step - loss: 478.8237 - acc: 0.1478 - val_loss: 470.6007 - val_acc: 0.1691\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 21s 707us/step - loss: 475.5601 - acc: 0.1500 - val_loss: 468.0968 - val_acc: 0.1777\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 21s 706us/step - loss: 472.7561 - acc: 0.1505 - val_loss: 466.0638 - val_acc: 0.1760\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 21s 706us/step - loss: 470.5919 - acc: 0.1519 - val_loss: 464.6496 - val_acc: 0.1793\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 21s 706us/step - loss: 469.0529 - acc: 0.1538 - val_loss: 463.1799 - val_acc: 0.1801\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 21s 706us/step - loss: 467.6854 - acc: 0.1556 - val_loss: 462.5629 - val_acc: 0.1770\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 21s 705us/step - loss: 466.4087 - acc: 0.1556 - val_loss: 462.6257 - val_acc: 0.1833\n"
     ]
    }
   ],
   "source": [
    "model1 = DeepCollab(batch_size=64, hidden_layers=3, user_features=True)\n",
    "model1.fit(train_data_users, denoised_train_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 10000)        100010000   input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 26)           702         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 10026)        0           dense_20[0][0]                   \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1024)         10267648    concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 512)          524800      dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 256)          131328      dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 512)          131584      dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1024)         525312      dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 10000)        10250000    dense_26[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 121,841,374\n",
      "Trainable params: 121,841,374\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 21s 712us/step - loss: 517.9774 - acc: 0.1057 - val_loss: 489.6004 - val_acc: 0.1915\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 21s 707us/step - loss: 488.8785 - acc: 0.1648 - val_loss: 474.6259 - val_acc: 0.1844\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 21s 708us/step - loss: 480.5055 - acc: 0.1654 - val_loss: 468.2684 - val_acc: 0.1880\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 21s 709us/step - loss: 476.4194 - acc: 0.1638 - val_loss: 465.7433 - val_acc: 0.1955\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 21s 708us/step - loss: 472.8171 - acc: 0.1668 - val_loss: 463.1106 - val_acc: 0.1891\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 21s 708us/step - loss: 470.1139 - acc: 0.1656 - val_loss: 462.7001 - val_acc: 0.1903\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 21s 708us/step - loss: 467.3141 - acc: 0.1629 - val_loss: 458.4559 - val_acc: 0.1876\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 21s 709us/step - loss: 465.3844 - acc: 0.1631 - val_loss: 458.6905 - val_acc: 0.1830\n"
     ]
    }
   ],
   "source": [
    "model2 = DeepCollab(batch_size=64, hidden_layers=5, user_features=True)\n",
    "model2.fit(train_data_users, denoised_train_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10000)        100010000   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 26)           702         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10026)        0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2048)         20535296    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         2098176     dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          524800      dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         525312      dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2048)         2099200     dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10000)        20490000    dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 146,283,486\n",
      "Trainable params: 146,283,486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 26s 857us/step - loss: 522.3655 - acc: 0.0919 - val_loss: 493.7461 - val_acc: 0.1781\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 25s 845us/step - loss: 492.6728 - acc: 0.1620 - val_loss: 477.1324 - val_acc: 0.1877\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 25s 846us/step - loss: 483.4966 - acc: 0.1655 - val_loss: 471.3493 - val_acc: 0.1853\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 25s 845us/step - loss: 478.8258 - acc: 0.1658 - val_loss: 467.6528 - val_acc: 0.1844\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 25s 844us/step - loss: 475.3281 - acc: 0.1637 - val_loss: 464.5996 - val_acc: 0.1884\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 25s 846us/step - loss: 471.5050 - acc: 0.1618 - val_loss: 460.4539 - val_acc: 0.1826\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 25s 847us/step - loss: 467.9374 - acc: 0.1604 - val_loss: 458.4956 - val_acc: 0.1801\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 25s 847us/step - loss: 465.8278 - acc: 0.1577 - val_loss: 456.7717 - val_acc: 0.1781\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 25s 845us/step - loss: 464.2992 - acc: 0.1572 - val_loss: 457.6699 - val_acc: 0.1788\n"
     ]
    }
   ],
   "source": [
    "model3 = DeepCollab(batch_size=64, hidden_layers=5, user_features=True, nodes=2048)\n",
    "model3.fit(train_data_users, denoised_train_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10000)        100010000   input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 26)           702         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 10026)        0           dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2048)         20535296    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 512)          524800      dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1024)         525312      dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 2048)         2099200     dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 10000)        20490000    dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 146,283,486\n",
      "Trainable params: 146,283,486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 525.9379 - acc: 0.1440 - val_loss: 493.4440 - val_acc: 0.1782\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 501.1253 - acc: 0.1691 - val_loss: 483.7963 - val_acc: 0.1861\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 491.6618 - acc: 0.1712 - val_loss: 477.8490 - val_acc: 0.1928\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 485.9761 - acc: 0.1712 - val_loss: 472.5476 - val_acc: 0.1915\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 481.0289 - acc: 0.1714 - val_loss: 468.7929 - val_acc: 0.1929\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 478.5570 - acc: 0.1715 - val_loss: 468.5189 - val_acc: 0.1900\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 475.5334 - acc: 0.1696 - val_loss: 464.2551 - val_acc: 0.1931\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 472.1946 - acc: 0.1699 - val_loss: 464.5733 - val_acc: 0.1911\n"
     ]
    }
   ],
   "source": [
    "model4 = DeepCollab(batch_size=32, hidden_layers=5, user_features=True, nodes=2048)\n",
    "model4.fit(train_data_users, denoised_train_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4.autoencoder.save('models/autoencoder_userfeatures_5star.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 10000)        100010000   input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 26)           702         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 10026)        0           dense_17[0][0]                   \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 2048)         20535296    concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1024)         2098176     dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 512)          524800      dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1024)         525312      dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 2048)         2099200     dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 10000)        20490000    dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 146,283,486\n",
      "Trainable params: 146,283,486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 465.3240 - acc: 0.2362 - val_loss: 447.2718 - val_acc: 0.2606\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 439.2214 - acc: 0.2378 - val_loss: 437.8824 - val_acc: 0.2637\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 430.0931 - acc: 0.2370 - val_loss: 433.0732 - val_acc: 0.2626\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 425.0435 - acc: 0.2362 - val_loss: 428.7791 - val_acc: 0.2594\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 422.2982 - acc: 0.2312 - val_loss: 426.5021 - val_acc: 0.2601\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 419.3069 - acc: 0.2337 - val_loss: 424.5333 - val_acc: 0.2681\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 416.4472 - acc: 0.2330 - val_loss: 421.8727 - val_acc: 0.2583\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 414.9080 - acc: 0.2328 - val_loss: 419.7274 - val_acc: 0.2570\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 411.8628 - acc: 0.2343 - val_loss: 417.6411 - val_acc: 0.2590\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 409.9364 - acc: 0.2298 - val_loss: 416.6896 - val_acc: 0.2543\n",
      "Epoch 11/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 408.3703 - acc: 0.2229 - val_loss: 415.2676 - val_acc: 0.2450\n",
      "Epoch 12/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 407.0353 - acc: 0.2224 - val_loss: 415.1405 - val_acc: 0.2451\n",
      "Epoch 13/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 405.6154 - acc: 0.2177 - val_loss: 414.0278 - val_acc: 0.2424\n",
      "Epoch 14/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 404.6211 - acc: 0.2171 - val_loss: 414.2506 - val_acc: 0.2305\n"
     ]
    }
   ],
   "source": [
    "model = DeepCollab(batch_size=32, hidden_layers=5, user_features=True, nodes=2048)\n",
    "model.fit(train_binary_data_users, denoised_train_binary_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 10000)        100010000   input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 26)           702         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 10026)        0           dense_25[0][0]                   \n",
      "                                                                 dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 2048)         20535296    concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1024)         2098176     dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 512)          524800      dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1024)         525312      dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 2048)         2099200     dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 10000)        20490000    dense_31[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 146,283,486\n",
      "Trainable params: 146,283,486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 26s 855us/step - loss: 463.3114 - acc: 0.1725 - val_loss: 446.9663 - val_acc: 0.2189\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 25s 848us/step - loss: 436.6591 - acc: 0.1893 - val_loss: 435.5274 - val_acc: 0.2035\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 25s 849us/step - loss: 426.3363 - acc: 0.2020 - val_loss: 431.4092 - val_acc: 0.2500\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 25s 851us/step - loss: 420.7072 - acc: 0.2200 - val_loss: 427.3437 - val_acc: 0.2437\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 25s 850us/step - loss: 417.0916 - acc: 0.2210 - val_loss: 424.2296 - val_acc: 0.2393\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 25s 849us/step - loss: 415.2297 - acc: 0.2230 - val_loss: 421.4734 - val_acc: 0.2478\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 25s 850us/step - loss: 412.7057 - acc: 0.2193 - val_loss: 420.4959 - val_acc: 0.2440\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 25s 851us/step - loss: 411.1423 - acc: 0.2149 - val_loss: 418.6765 - val_acc: 0.2331\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 25s 851us/step - loss: 409.8744 - acc: 0.2121 - val_loss: 418.8507 - val_acc: 0.2417\n"
     ]
    }
   ],
   "source": [
    "model1 = DeepCollab(batch_size=64, hidden_layers=5, user_features=True, nodes=2048)\n",
    "model1.fit(train_binary_data_users, denoised_train_binary_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 10000)        100010000   input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 26)           702         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 10026)        0           dense_33[0][0]                   \n",
      "                                                                 dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 2048)         20535296    concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 1024)         2098176     dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 512)          524800      dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 1024)         525312      dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 2048)         2099200     dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 10000)        20490000    dense_39[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 146,283,486\n",
      "Trainable params: 146,283,486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 14s 481us/step - loss: 469.5044 - acc: 0.0620 - val_loss: 447.7666 - val_acc: 0.0870\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 14s 477us/step - loss: 438.4561 - acc: 0.1597 - val_loss: 438.2240 - val_acc: 0.2241\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 14s 476us/step - loss: 429.3563 - acc: 0.2056 - val_loss: 432.5745 - val_acc: 0.2230\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 14s 480us/step - loss: 424.7076 - acc: 0.2112 - val_loss: 428.8653 - val_acc: 0.2363\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 14s 476us/step - loss: 421.5178 - acc: 0.2157 - val_loss: 424.7403 - val_acc: 0.2405\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 14s 476us/step - loss: 417.2659 - acc: 0.2163 - val_loss: 420.6519 - val_acc: 0.2305\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 14s 480us/step - loss: 413.4010 - acc: 0.2092 - val_loss: 418.3360 - val_acc: 0.2331\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 14s 474us/step - loss: 410.3936 - acc: 0.2114 - val_loss: 415.4155 - val_acc: 0.2339\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 14s 479us/step - loss: 408.1741 - acc: 0.2135 - val_loss: 416.0846 - val_acc: 0.2421\n"
     ]
    }
   ],
   "source": [
    "model2 = DeepCollab(batch_size=128, hidden_layers=5, user_features=True, nodes=2048)\n",
    "model2.fit(train_binary_data_users, denoised_train_binary_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.autoencoder.save('models/cdae_binary.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16026, 10000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_users = pd.read_csv('data/backups/autoencoder_test.csv', header=0)\n",
    "test_users = list(set(test_data_users['user_id'].tolist()))\n",
    "test_data_users['rating'] = test_data_users.apply(lambda x: x['rating']/5, axis=1)\n",
    "test_data_users = test_data_users.pivot(index='user_id', columns='book_id')\n",
    "test_data_users.fillna(0, inplace=True)\n",
    "test_data_users = np.asarray(test_data_users)\n",
    "test_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voldemort/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16026, 10000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised_test_data_users = full_ratings[full_ratings['user_id'].isin(test_users)]\n",
    "denoised_test_data_users['rating'] = denoised_test_data_users.apply(lambda x: x['rating']/5, axis=1)\n",
    "denoised_test_data_users = denoised_test_data_users.pivot(index='user_id', columns='book_id')\n",
    "denoised_test_data_users.fillna(0, inplace=True)\n",
    "denoised_test_data_users = np.asarray(denoised_test_data_users)\n",
    "denoised_test_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16026, 26)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features = pd.read_csv('data/user_features_final.csv')\n",
    "test_user_features = user_features[user_features['user_id'].isin(list(test_users))].copy()\n",
    "test_user_features['avg_rating'] = test_user_features.apply(lambda x: x['avg_rating']/5, axis=1)\n",
    "test_user_features.drop('user_id', axis=1, inplace=True)\n",
    "test_user_features = np.asarray(test_user_features)\n",
    "test_user_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16026, 10000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_binary_data_users = pd.read_csv('data/backups/autoencoder_test.csv', header=0)\n",
    "\n",
    "test_binary_data_users['rating'] = test_binary_data_users.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "test_binary_data_users = test_binary_data_users.pivot(index='user_id', columns='book_id')\n",
    "test_binary_data_users.fillna(0, inplace=True)\n",
    "test_binary_data_users = np.asarray(test_binary_data_users)\n",
    "test_binary_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voldemort/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16026, 10000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised_test_binary_data_users = full_ratings[full_ratings['user_id'].isin(test_users)]\n",
    "denoised_test_binary_data_users['rating'] = denoised_test_binary_data_users.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "denoised_test_binary_data_users = denoised_test_binary_data_users.pivot(index='user_id', columns='book_id')\n",
    "denoised_test_binary_data_users.fillna(0, inplace=True)\n",
    "denoised_test_binary_data_users = np.asarray(denoised_test_binary_data_users)\n",
    "denoised_test_binary_data_users.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16026/16026 [==============================] - 3s 216us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model4.predict(test_data_users, test_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.dump('data/backups/cdae_5star_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16026, 10000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1158</td>\n",
       "      <td>0.566804</td>\n",
       "      <td>3</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2411</td>\n",
       "      <td>0.330137</td>\n",
       "      <td>4</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148</td>\n",
       "      <td>0.869025</td>\n",
       "      <td>4</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>0.113886</td>\n",
       "      <td>4</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291</td>\n",
       "      <td>0.200990</td>\n",
       "      <td>5</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  pred_proba  rating  user_id\n",
       "0     1158    0.566804       3    32771\n",
       "1     2411    0.330137       4    32771\n",
       "2      148    0.869025       4    32771\n",
       "3      195    0.113886       4    32771\n",
       "4      291    0.200990       5    32771"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings = pd.read_csv('data/backups/autoencoder_train.csv', header=0)\n",
    "full_ratings = pd.read_csv('data/unprocessed/ratings.csv', header=0)\n",
    "\n",
    "pred_dfs = []\n",
    "\n",
    "for index, user in enumerate(test_users):\n",
    "    train_books = train_ratings[train_ratings['user_id'] == user]['book_id'].tolist()\n",
    "    all_books = full_ratings[full_ratings['user_id'] == user]['book_id'].tolist()\n",
    "    test_books = [book for book in all_books if book not in train_books]\n",
    "    idx = [b - 1 for b in test_books]\n",
    "    filter_books = full_ratings[full_ratings['user_id'] == user]\n",
    "    test_book_ratings = filter_books[filter_books['book_id'].isin(test_books)]['rating'].tolist()\n",
    "\n",
    "    #print(len(test_book_ratings))\n",
    "    raw_predictions = predictions[index]\n",
    "    raw_predictions = raw_predictions[idx]\n",
    "    #print(raw_predictions.shape)\n",
    "    df = pd.DataFrame({'book_id': test_books, \n",
    "                       'rating': test_book_ratings,\n",
    "\n",
    "                       'pred_proba': raw_predictions})\n",
    "    df['user_id'] = user\n",
    "    pred_dfs.append(df)\n",
    "    \n",
    "evaluate_df = pd.concat(pred_dfs, ignore_index=True)\n",
    "\n",
    "evaluate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_df.to_csv('cdae_5star_evaluate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_eval = pd.read_csv('data/cdae_5star_evaluate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1410663\n",
       "2.0     306733\n",
       "3.0      69737\n",
       "4.0       2328\n",
       "5.0          2\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reverse the original scaling\n",
    "star_eval['scaled_raw'] = star_eval.apply(lambda x: x['pred_proba'] * 5, axis=1)\n",
    "\n",
    "min_p = star_eval['scaled_raw'].min()\n",
    "max_p = star_eval['scaled_raw'].max()\n",
    "\n",
    "# Ref: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "def scale_prediction(x, min_p, max_p):\n",
    "    raw = (x - min_p) / (max_p - min_p)\n",
    "    return np.rint(raw * 4) + 1\n",
    "\n",
    "star_eval['prediction'] = star_eval.apply(lambda x: scale_prediction(x['scaled_raw'], min_p, max_p), axis=1)\n",
    "star_eval['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm, p, r = ev.replay_5star_results(star_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 27808,   8031,   1362,     17,      0],\n",
       "       [ 85429,  18544,   3210,     67,      0],\n",
       "       [335845,  64964,  11421,    294,      0],\n",
       "       [512056, 106961,  22811,    708,      0],\n",
       "       [449525, 108233,  30933,   1242,      2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48065991265173286 0.03268187160058632\n"
     ]
    }
   ],
   "source": [
    "print(p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py:526: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users evaluated\n",
      "500 users evaluated\n",
      "1000 users evaluated\n",
      "1500 users evaluated\n",
      "2000 users evaluated\n",
      "2500 users evaluated\n",
      "3000 users evaluated\n",
      "3500 users evaluated\n",
      "4000 users evaluated\n",
      "4500 users evaluated\n",
      "5000 users evaluated\n",
      "5500 users evaluated\n",
      "6000 users evaluated\n",
      "6500 users evaluated\n",
      "7000 users evaluated\n",
      "7500 users evaluated\n",
      "8000 users evaluated\n",
      "8500 users evaluated\n",
      "9000 users evaluated\n",
      "9500 users evaluated\n",
      "10000 users evaluated\n",
      "10500 users evaluated\n",
      "11000 users evaluated\n",
      "11500 users evaluated\n",
      "12000 users evaluated\n",
      "12500 users evaluated\n",
      "13000 users evaluated\n",
      "13500 users evaluated\n",
      "14000 users evaluated\n",
      "14500 users evaluated\n",
      "15000 users evaluated\n",
      "15500 users evaluated\n",
      "16000 users evaluated\n"
     ]
    }
   ],
   "source": [
    "aps, mAP, binary_mAP, binary_aps, skipped = ev.top_n_5star_results(star_eval, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04473979782852864 0.6709846499438413 0\n"
     ]
    }
   ],
   "source": [
    "print(mAP, binary_mAP, skipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16026/16026 [==============================] - 4s 221us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model2.predict(test_data_users, test_user_features)\n",
    "predictions.dump('data/backups/cdae_binary_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1158</td>\n",
       "      <td>0.508821</td>\n",
       "      <td>3</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2411</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>4</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148</td>\n",
       "      <td>1.192314</td>\n",
       "      <td>4</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>0.153827</td>\n",
       "      <td>4</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291</td>\n",
       "      <td>0.317180</td>\n",
       "      <td>5</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  pred_proba  rating  user_id\n",
       "0     1158    0.508821       3    32771\n",
       "1     2411    0.014855       4    32771\n",
       "2      148    1.192314       4    32771\n",
       "3      195    0.153827       4    32771\n",
       "4      291    0.317180       5    32771"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings = pd.read_csv('data/backups/autoencoder_train.csv', header=0)\n",
    "full_ratings = pd.read_csv('data/unprocessed/ratings.csv', header=0)\n",
    "\n",
    "pred_dfs = []\n",
    "\n",
    "for index, user in enumerate(test_users):\n",
    "    train_books = train_ratings[train_ratings['user_id'] == user]['book_id'].tolist()\n",
    "    all_books = full_ratings[full_ratings['user_id'] == user]['book_id'].tolist()\n",
    "    test_books = [book for book in all_books if book not in train_books]\n",
    "    idx = [b - 1 for b in test_books]\n",
    "    filter_books = full_ratings[full_ratings['user_id'] == user]\n",
    "    test_book_ratings = filter_books[filter_books['book_id'].isin(test_books)]['rating'].tolist()\n",
    "\n",
    "    #print(len(test_book_ratings))\n",
    "    raw_predictions = predictions[index]\n",
    "    raw_predictions = raw_predictions[idx]\n",
    "    #print(raw_predictions.shape)\n",
    "    df = pd.DataFrame({'book_id': test_books, \n",
    "                       'rating': test_book_ratings,\n",
    "                       'pred_proba': raw_predictions})\n",
    "    df['user_id'] = user\n",
    "    pred_dfs.append(df)\n",
    "    \n",
    "evaluate_df = pd.concat(pred_dfs, ignore_index=True)\n",
    "\n",
    "evaluate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_df.to_csv('cdae_binary_evaluate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1158</td>\n",
       "      <td>0.508822</td>\n",
       "      <td>3</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2411</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>4</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148</td>\n",
       "      <td>1.192314</td>\n",
       "      <td>4</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>0.153827</td>\n",
       "      <td>4</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291</td>\n",
       "      <td>0.317180</td>\n",
       "      <td>5</td>\n",
       "      <td>32771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  pred_proba  rating  user_id\n",
       "0     1158    0.508822       3    32771\n",
       "1     2411    0.014855       4    32771\n",
       "2      148    1.192314       4    32771\n",
       "3      195    0.153827       4    32771\n",
       "4      291    0.317180       5    32771"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_eval = pd.read_csv('data/cdae_binary_evaluate.csv')\n",
    "binary_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_eval['binary_rating'] = binary_eval.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1731176\n",
       "1.0      58287\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_p = binary_eval['pred_proba'].min()\n",
    "max_p = binary_eval['pred_proba'].max()\n",
    "\n",
    "def scale_prediction_binary(x, min_p, max_p):\n",
    "    raw = (x - min_p) / (max_p - min_p)\n",
    "    return np.rint(raw)\n",
    "\n",
    "binary_eval['prediction'] = binary_eval.apply(lambda x: scale_prediction_binary(x['pred_proba'], min_p, max_p), axis=1)\n",
    "binary_eval['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm, p, r = ev.replay_binary_results(binary_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 545269,   11723],\n",
       "       [1185907,   46564]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7988745346303635 0.03778101066881087\n"
     ]
    }
   ],
   "source": [
    "print(p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py:526: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 users evaluated\n",
      "1000 users evaluated\n",
      "1500 users evaluated\n",
      "2000 users evaluated\n",
      "2500 users evaluated\n",
      "3000 users evaluated\n",
      "3500 users evaluated\n",
      "4000 users evaluated\n",
      "4500 users evaluated\n",
      "5000 users evaluated\n",
      "5500 users evaluated\n",
      "6000 users evaluated\n",
      "6500 users evaluated\n",
      "7000 users evaluated\n",
      "7500 users evaluated\n",
      "8000 users evaluated\n",
      "8500 users evaluated\n",
      "9000 users evaluated\n",
      "9500 users evaluated\n",
      "10000 users evaluated\n",
      "10500 users evaluated\n",
      "11000 users evaluated\n",
      "11500 users evaluated\n",
      "12000 users evaluated\n",
      "12500 users evaluated\n",
      "13000 users evaluated\n",
      "13500 users evaluated\n",
      "14000 users evaluated\n",
      "14500 users evaluated\n",
      "15000 users evaluated\n",
      "15500 users evaluated\n",
      "16000 users evaluated\n"
     ]
    }
   ],
   "source": [
    "mAP, skipped = ev.top_n_binary_results(binary_eval, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6628229127667541"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cold Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cold_start_features = np.zeros((1, 26))\n",
    "cold_start_ratings = np.zeros((1, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 26)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_start_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "cold_start = model4.predict(cold_start_ratings, cold_start_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.567486  , 4.439316  , 2.8567214 , ..., 0.        , 0.06534243,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cold_start.dump('data/backups/cold_start_5star_cdae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart_5star = np.load('data/backups/cold_start_5star_cdae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_start_users = pd.read_csv('data/cold_start_ratings_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>1.033080</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>268</td>\n",
       "      <td>0.872772</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3638</td>\n",
       "      <td>0.051928</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1796</td>\n",
       "      <td>0.136489</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  pred_proba  rating  user_id\n",
       "0      258    1.033080       5        1\n",
       "1      268    0.872772       3        1\n",
       "2     5556    0.000000       3        1\n",
       "3     3638    0.051928       3        1\n",
       "4     1796    0.136489       5        1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dfs = []\n",
    "users = list(set(cold_start_users['user_id'].tolist()))\n",
    "\n",
    "for index, user in enumerate(users):\n",
    "    \n",
    "    all_books = cold_start_users[cold_start_users['user_id'] == user]['book_id'].tolist()\n",
    "    idx = [b - 1 for b in all_books]\n",
    "    filter_books = cold_start_users[cold_start_users['user_id'] == user]\n",
    "    test_book_ratings = filter_books[filter_books['book_id'].isin(all_books)]['rating'].tolist()\n",
    "\n",
    "    #print(len(test_book_ratings))\n",
    "\n",
    "    raw_predictions = coldstart_5star[:,idx]\n",
    "\n",
    "    #print(raw_predictions.shape)\n",
    "    df = pd.DataFrame({'book_id': all_books, \n",
    "                       'rating': test_book_ratings,\n",
    "                       'pred_proba': raw_predictions[0]})\n",
    "    df['user_id'] = user\n",
    "    pred_dfs.append(df)\n",
    "    \n",
    "evaluate_df = pd.concat(pred_dfs, ignore_index=True)\n",
    "\n",
    "evaluate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.439316 , 2.8567214, 4.2510595]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldstart_5star[:, [1, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    322\n",
       "2.0    113\n",
       "3.0     47\n",
       "4.0     20\n",
       "5.0      5\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_df['scaled_raw'] = star_eval.apply(lambda x: x['pred_proba'] * 5, axis=1)\n",
    "\n",
    "min_p = evaluate_df['scaled_raw'].min()\n",
    "max_p = evaluate_df['scaled_raw'].max()\n",
    "\n",
    "# Ref: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "def scale_prediction(x, min_p, max_p):\n",
    "    raw = (x - min_p) / (max_p - min_p)\n",
    "    return np.rint(raw * 4) + 1\n",
    "\n",
    "evaluate_df['prediction'] = evaluate_df.apply(lambda x: scale_prediction(x['scaled_raw'], min_p, max_p), axis=1)\n",
    "evaluate_df['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35,  10,   2,   7,   2],\n",
       "       [ 22,  11,   7,   2,   0],\n",
       "       [ 79,  28,  13,   1,   1],\n",
       "       [114,  36,  12,   5,   0],\n",
       "       [ 72,  28,  13,   5,   2]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm, p, r = ev.replay_5star_results(evaluate_df)\n",
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26364917741227656 0.1301775147928994\n"
     ]
    }
   ],
   "source": [
    "print(p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py:526: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users evaluated\n"
     ]
    }
   ],
   "source": [
    "aps, mAP, binary_mAP, binary_aps, skipped = ev.top_n_5star_results(evaluate_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.131628  , 4.276492  , 1.8483028 , ..., 0.04341072, 0.08637094,\n",
       "        0.03407854]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_start2 = model2.predict(cold_start_ratings, cold_start_features)\n",
    "cold_start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cold_start2.dump('data/backups/cold_start_binary_cdae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>0.937875</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>268</td>\n",
       "      <td>0.951219</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5556</td>\n",
       "      <td>0.049214</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3638</td>\n",
       "      <td>0.148281</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1796</td>\n",
       "      <td>0.218136</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  pred_proba  rating  user_id\n",
       "0      258    0.937875       5        1\n",
       "1      268    0.951219       3        1\n",
       "2     5556    0.049214       3        1\n",
       "3     3638    0.148281       3        1\n",
       "4     1796    0.218136       5        1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_start_binary = np.load('data/backups/cold_start_binary_cdae')\n",
    "\n",
    "pred_dfs = []\n",
    "users = list(set(cold_start_users['user_id'].tolist()))\n",
    "\n",
    "for index, user in enumerate(users):\n",
    "    \n",
    "    all_books = cold_start_users[cold_start_users['user_id'] == user]['book_id'].tolist()\n",
    "    idx = [b - 1 for b in all_books]\n",
    "    filter_books = cold_start_users[cold_start_users['user_id'] == user]\n",
    "    test_book_ratings = filter_books[filter_books['book_id'].isin(all_books)]['rating'].tolist()\n",
    "\n",
    "    #print(len(test_book_ratings))\n",
    "\n",
    "    raw_predictions = cold_start_binary[:,idx]\n",
    "\n",
    "    #print(raw_predictions.shape)\n",
    "    df = pd.DataFrame({'book_id': all_books, \n",
    "                       'rating': test_book_ratings,\n",
    "                       'pred_proba': raw_predictions[0]})\n",
    "    df['user_id'] = user\n",
    "    pred_dfs.append(df)\n",
    "    \n",
    "evaluate_df = pd.concat(pred_dfs, ignore_index=True)\n",
    "\n",
    "evaluate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    443\n",
       "1.0     64\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_df['binary_rating'] = evaluate_df.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "\n",
    "min_p = evaluate_df['pred_proba'].min()\n",
    "max_p = evaluate_df['pred_proba'].max()\n",
    "\n",
    "def scale_prediction_binary(x, min_p, max_p):\n",
    "    raw = (x - min_p) / (max_p - min_p)\n",
    "    return np.rint(raw)\n",
    "\n",
    "evaluate_df['prediction'] = evaluate_df.apply(lambda x: scale_prediction_binary(x['pred_proba'], min_p, max_p), axis=1)\n",
    "evaluate_df['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[203,  17],\n",
       "       [240,  47]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm, p, r = ev.replay_binary_results(evaluate_df)\n",
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734375 0.16376306620209058\n"
     ]
    }
   ],
   "source": [
    "print(p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py:526: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    }
   ],
   "source": [
    "mAP, skipped = ev.top_n_binary_results(evaluate_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
