{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voldemort/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "#from recsys.collaborative_deep_learing import DeepCollab\n",
    "\n",
    "from keras.layers import Dense, Input, Concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings = pd.read_csv('data/train_ratings_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1496995\n",
       "5    1388429\n",
       "3     959931\n",
       "2     250846\n",
       "1      86979\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                                        ...   \\\n",
       "book_id  1     2     3     4     5     6     7     8     9     10     ...    \n",
       "user_id                                                               ...    \n",
       "6          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "7          NaN   NaN   NaN   NaN   3.0   NaN   NaN   2.0   NaN   NaN  ...    \n",
       "8          NaN   NaN   NaN   3.0   3.0   NaN   NaN   NaN   NaN   1.0  ...    \n",
       "9          4.0   4.0   4.0   NaN   NaN   NaN   NaN   NaN   1.0   5.0  ...    \n",
       "10         NaN   NaN   NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "\n",
       "                                                                     \n",
       "book_id 9991  9992  9993  9994  9995  9996  9997  9998  9999  10000  \n",
       "user_id                                                              \n",
       "6         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "7         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "8         1.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "9         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "10        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings = train_ratings.pivot(index='user_id', columns='book_id')\n",
    "train_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings_noisy = pd.read_csv('data/train_ratings_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(7)\n",
    "\n",
    "# 5% noise\n",
    "for _ in range(int(len(train_ratings_noisy) / 20)):\n",
    "    i = random.randint(0, len(train_ratings_noisy))\n",
    "    train_ratings_noisy.iloc[i]['rating'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1424262\n",
       "5    1320247\n",
       "3     913261\n",
       "2     238649\n",
       "0     204066\n",
       "1      82695\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings_noisy['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings_noisy = train_ratings_noisy.pivot(index='user_id', columns='book_id')\n",
    "train_ratings_noisy.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings.to_csv('data/backups/train_ratings_pivot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings_noisy.to_csv('data/backups/train_ratings_noisy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings = pd.read_csv('data/backups/train_ratings_pivot.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings_noisy = pd.read_csv('data/backups/train_ratings_noisy.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53420, 10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53419, 10000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>rating.1</th>\n",
       "      <th>rating.2</th>\n",
       "      <th>rating.3</th>\n",
       "      <th>rating.4</th>\n",
       "      <th>rating.5</th>\n",
       "      <th>rating.6</th>\n",
       "      <th>rating.7</th>\n",
       "      <th>rating.8</th>\n",
       "      <th>rating.9</th>\n",
       "      <th>...</th>\n",
       "      <th>rating.9990</th>\n",
       "      <th>rating.9991</th>\n",
       "      <th>rating.9992</th>\n",
       "      <th>rating.9993</th>\n",
       "      <th>rating.9994</th>\n",
       "      <th>rating.9995</th>\n",
       "      <th>rating.9996</th>\n",
       "      <th>rating.9997</th>\n",
       "      <th>rating.9998</th>\n",
       "      <th>rating.9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  rating.1  rating.2  rating.3  rating.4  rating.5  rating.6  \\\n",
       "1     0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2     0.0       0.0       0.0       0.0       3.0       0.0       0.0   \n",
       "3     0.0       0.0       0.0       3.0       3.0       0.0       0.0   \n",
       "4     4.0       4.0       4.0       0.0       0.0       0.0       0.0   \n",
       "5     0.0       0.0       0.0       5.0       0.0       0.0       0.0   \n",
       "\n",
       "   rating.7  rating.8  rating.9     ...       rating.9990  rating.9991  \\\n",
       "1       0.0       0.0       0.0     ...               0.0          0.0   \n",
       "2       2.0       0.0       0.0     ...               0.0          0.0   \n",
       "3       0.0       0.0       1.0     ...               1.0          0.0   \n",
       "4       0.0       1.0       5.0     ...               0.0          0.0   \n",
       "5       0.0       0.0       0.0     ...               0.0          0.0   \n",
       "\n",
       "   rating.9992  rating.9993  rating.9994  rating.9995  rating.9996  \\\n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "5          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   rating.9997  rating.9998  rating.9999  \n",
       "1          0.0          0.0          0.0  \n",
       "2          0.0          0.0          0.0  \n",
       "3          0.0          0.0          0.0  \n",
       "4          0.0          0.0          0.0  \n",
       "5          0.0          0.0          0.0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings.drop(0, axis=0, inplace=True)\n",
    "train_ratings_noisy.drop(0, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings_noisy = np.asarray(train_ratings_noisy)\n",
    "train_ratings = np.asarray(train_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Denoising Autoencoder\n",
    "## 5 Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DeepCollab(batch_size=128, hidden_layers=1, user_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 120,501,024\n",
      "Trainable params: 120,501,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 42735 samples, validate on 10684 samples\n",
      "Epoch 1/100\n",
      "42735/42735 [==============================] - 31s 723us/step - loss: 3135.0102 - acc: 0.1445 - val_loss: 3057.5919 - val_acc: 0.1574\n",
      "Epoch 2/100\n",
      "42735/42735 [==============================] - 31s 722us/step - loss: 3098.3097 - acc: 0.1352 - val_loss: 3048.8599 - val_acc: 0.1444\n",
      "Epoch 3/100\n",
      "42735/42735 [==============================] - 31s 721us/step - loss: 3089.1370 - acc: 0.1310 - val_loss: 3042.4157 - val_acc: 0.1367\n",
      "Epoch 4/100\n",
      "42735/42735 [==============================] - 31s 721us/step - loss: 3081.0342 - acc: 0.1307 - val_loss: 3038.2444 - val_acc: 0.1161\n",
      "Epoch 5/100\n",
      "42735/42735 [==============================] - 31s 722us/step - loss: 3075.3404 - acc: 0.1219 - val_loss: 3035.8444 - val_acc: 0.1199\n",
      "Epoch 6/100\n",
      "42735/42735 [==============================] - 31s 722us/step - loss: 3072.8206 - acc: 0.1236 - val_loss: 3033.5520 - val_acc: 0.1350\n",
      "Epoch 7/100\n",
      "42735/42735 [==============================] - 31s 723us/step - loss: 3068.3734 - acc: 0.1191 - val_loss: 3032.1113 - val_acc: 0.1267\n",
      "Epoch 8/100\n",
      "42735/42735 [==============================] - 31s 723us/step - loss: 3063.5424 - acc: 0.1206 - val_loss: 3029.7747 - val_acc: 0.1128\n",
      "Epoch 9/100\n",
      "42735/42735 [==============================] - 31s 724us/step - loss: 3061.6543 - acc: 0.1143 - val_loss: 3028.8854 - val_acc: 0.1231\n",
      "Epoch 10/100\n",
      "42735/42735 [==============================] - 31s 722us/step - loss: 3059.1388 - acc: 0.1143 - val_loss: 3026.4527 - val_acc: 0.1413\n",
      "Epoch 11/100\n",
      "42735/42735 [==============================] - 31s 722us/step - loss: 3056.4712 - acc: 0.1172 - val_loss: 3027.9753 - val_acc: 0.1250\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ratings_noisy, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = DeepCollab(batch_size=128, hidden_layers=3, user_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,551,136\n",
      "Trainable params: 121,551,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 42735 samples, validate on 10684 samples\n",
      "Epoch 1/100\n",
      "42735/42735 [==============================] - 31s 730us/step - loss: 2462.6704 - acc: 0.0583 - val_loss: 2294.0173 - val_acc: 0.1081\n",
      "Epoch 2/100\n",
      "42735/42735 [==============================] - 31s 729us/step - loss: 2318.0738 - acc: 0.1015 - val_loss: 2250.5787 - val_acc: 0.1270\n",
      "Epoch 3/100\n",
      "42735/42735 [==============================] - 31s 729us/step - loss: 2285.4011 - acc: 0.1185 - val_loss: 2235.1478 - val_acc: 0.1439\n",
      "Epoch 4/100\n",
      "42735/42735 [==============================] - 31s 728us/step - loss: 2266.0078 - acc: 0.1264 - val_loss: 2223.1420 - val_acc: 0.1520\n",
      "Epoch 5/100\n",
      "42735/42735 [==============================] - 31s 729us/step - loss: 2250.1119 - acc: 0.1325 - val_loss: 2221.6786 - val_acc: 0.1480\n",
      "Epoch 6/100\n",
      "42735/42735 [==============================] - 31s 729us/step - loss: 2237.5056 - acc: 0.1359 - val_loss: 2202.5733 - val_acc: 0.1613\n",
      "Epoch 7/100\n",
      "42735/42735 [==============================] - 31s 728us/step - loss: 2224.7223 - acc: 0.1358 - val_loss: 2198.6301 - val_acc: 0.1631\n",
      "Epoch 8/100\n",
      "42735/42735 [==============================] - 31s 727us/step - loss: 2215.8295 - acc: 0.1381 - val_loss: 2191.0014 - val_acc: 0.1533\n",
      "Epoch 9/100\n",
      "42735/42735 [==============================] - 31s 728us/step - loss: 2209.3070 - acc: 0.1375 - val_loss: 2190.3348 - val_acc: 0.1578\n",
      "Epoch 10/100\n",
      "42735/42735 [==============================] - 31s 729us/step - loss: 2201.9131 - acc: 0.1378 - val_loss: 2184.1977 - val_acc: 0.1580\n",
      "Epoch 11/100\n",
      "42735/42735 [==============================] - 31s 728us/step - loss: 2197.0150 - acc: 0.1346 - val_loss: 2181.3944 - val_acc: 0.1521\n",
      "Epoch 12/100\n",
      "42735/42735 [==============================] - 31s 729us/step - loss: 2189.7000 - acc: 0.1359 - val_loss: 2178.5618 - val_acc: 0.1540\n",
      "Epoch 13/100\n",
      "42735/42735 [==============================] - 31s 729us/step - loss: 2184.5991 - acc: 0.1354 - val_loss: 2176.8319 - val_acc: 0.1551\n",
      "Epoch 14/100\n",
      "42735/42735 [==============================] - 31s 729us/step - loss: 2180.4676 - acc: 0.1338 - val_loss: 2174.2386 - val_acc: 0.1493\n",
      "Epoch 15/100\n",
      "42735/42735 [==============================] - 31s 730us/step - loss: 2175.4574 - acc: 0.1347 - val_loss: 2172.6635 - val_acc: 0.1492\n",
      "Epoch 16/100\n",
      "42735/42735 [==============================] - 31s 728us/step - loss: 2172.0851 - acc: 0.1334 - val_loss: 2169.6394 - val_acc: 0.1485\n",
      "Epoch 17/100\n",
      "42735/42735 [==============================] - 31s 729us/step - loss: 2167.7020 - acc: 0.1323 - val_loss: 2168.8450 - val_acc: 0.1497\n",
      "Epoch 18/100\n",
      "42735/42735 [==============================] - 31s 729us/step - loss: 2164.1695 - acc: 0.1307 - val_loss: 2168.9340 - val_acc: 0.1470\n"
     ]
    }
   ],
   "source": [
    "model2.fit(train_ratings_noisy, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,551,136\n",
      "Trainable params: 121,551,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 42735 samples, validate on 10684 samples\n",
      "Epoch 1/100\n",
      "42735/42735 [==============================] - 24s 572us/step - loss: 2516.1123 - acc: 0.0504 - val_loss: 2307.8793 - val_acc: 0.0771\n",
      "Epoch 2/100\n",
      "42735/42735 [==============================] - 24s 569us/step - loss: 2313.5502 - acc: 0.0901 - val_loss: 2246.4286 - val_acc: 0.0923\n",
      "Epoch 3/100\n",
      "42735/42735 [==============================] - 24s 569us/step - loss: 2273.2587 - acc: 0.0981 - val_loss: 2221.8766 - val_acc: 0.1108\n",
      "Epoch 4/100\n",
      "42735/42735 [==============================] - 24s 569us/step - loss: 2254.3819 - acc: 0.1109 - val_loss: 2210.2043 - val_acc: 0.1211\n",
      "Epoch 5/100\n",
      "42735/42735 [==============================] - 24s 569us/step - loss: 2235.7936 - acc: 0.1119 - val_loss: 2201.9031 - val_acc: 0.1219\n",
      "Epoch 6/100\n",
      "42735/42735 [==============================] - 24s 569us/step - loss: 2223.1329 - acc: 0.1136 - val_loss: 2192.8417 - val_acc: 0.1246\n",
      "Epoch 7/100\n",
      "42735/42735 [==============================] - 24s 569us/step - loss: 2212.7419 - acc: 0.1188 - val_loss: 2184.8520 - val_acc: 0.1294\n",
      "Epoch 8/100\n",
      "42735/42735 [==============================] - 24s 569us/step - loss: 2204.1873 - acc: 0.1233 - val_loss: 2184.5481 - val_acc: 0.1329\n",
      "Epoch 9/100\n",
      "42735/42735 [==============================] - 24s 569us/step - loss: 2197.5857 - acc: 0.1241 - val_loss: 2179.9274 - val_acc: 0.1305\n",
      "Epoch 10/100\n",
      "42735/42735 [==============================] - 24s 568us/step - loss: 2188.9611 - acc: 0.1238 - val_loss: 2174.8495 - val_acc: 0.1342\n",
      "Epoch 11/100\n",
      "42735/42735 [==============================] - 24s 570us/step - loss: 2181.4883 - acc: 0.1257 - val_loss: 2172.5603 - val_acc: 0.1344\n",
      "Epoch 12/100\n",
      "42735/42735 [==============================] - 24s 568us/step - loss: 2177.8048 - acc: 0.1263 - val_loss: 2169.7773 - val_acc: 0.1333\n",
      "Epoch 13/100\n",
      "42735/42735 [==============================] - 24s 569us/step - loss: 2171.9425 - acc: 0.1272 - val_loss: 2171.2653 - val_acc: 0.1344\n"
     ]
    }
   ],
   "source": [
    "model3 = DeepCollab(batch_size=256, hidden_layers=3, user_features=False)\n",
    "model3.fit(train_ratings_noisy, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,551,136\n",
      "Trainable params: 121,551,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 42735 samples, validate on 10684 samples\n",
      "Epoch 1/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3361.8534 - acc: 0.1544 - val_loss: 3305.5757 - val_acc: 0.1791\n",
      "Epoch 2/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3343.1746 - acc: 0.1595 - val_loss: 3303.9894 - val_acc: 0.1834\n",
      "Epoch 3/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3335.5919 - acc: 0.1615 - val_loss: 3289.2828 - val_acc: 0.1799\n",
      "Epoch 4/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3330.3652 - acc: 0.1577 - val_loss: 3286.6276 - val_acc: 0.1777\n",
      "Epoch 5/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3326.7327 - acc: 0.1576 - val_loss: 3285.8707 - val_acc: 0.1705\n",
      "Epoch 6/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3324.9667 - acc: 0.1542 - val_loss: 3283.1323 - val_acc: 0.1752\n",
      "Epoch 7/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3321.7623 - acc: 0.1525 - val_loss: 3281.0223 - val_acc: 0.1712\n",
      "Epoch 8/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3320.4057 - acc: 0.1509 - val_loss: 3280.1443 - val_acc: 0.1762\n",
      "Epoch 9/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3317.4442 - acc: 0.1521 - val_loss: 3280.1201 - val_acc: 0.1824\n",
      "Epoch 10/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3316.4901 - acc: 0.1530 - val_loss: 3277.0425 - val_acc: 0.1712\n",
      "Epoch 11/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3315.0020 - acc: 0.1497 - val_loss: 3276.5999 - val_acc: 0.1606\n",
      "Epoch 12/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3313.9520 - acc: 0.1489 - val_loss: 3275.7256 - val_acc: 0.1706\n",
      "Epoch 13/100\n",
      "42735/42735 [==============================] - 46s 1ms/step - loss: 3313.0032 - acc: 0.1490 - val_loss: 3279.7161 - val_acc: 0.1732\n"
     ]
    }
   ],
   "source": [
    "model4 = DeepCollab(batch_size=64, hidden_layers=3, user_features=False)\n",
    "model4.fit(train_ratings_noisy, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2048)              20482048  \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10000)             20490000  \n",
      "=================================================================\n",
      "Total params: 146,229,536\n",
      "Trainable params: 146,229,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 42735 samples, validate on 10684 samples\n",
      "Epoch 1/100\n",
      "42735/42735 [==============================] - 34s 805us/step - loss: 3177.0401 - acc: 0.1352 - val_loss: 3122.8528 - val_acc: 0.1700\n",
      "Epoch 2/100\n",
      "42735/42735 [==============================] - 34s 802us/step - loss: 3148.8964 - acc: 0.1547 - val_loss: 3094.5689 - val_acc: 0.1815\n",
      "Epoch 3/100\n",
      "42735/42735 [==============================] - 34s 803us/step - loss: 3133.7065 - acc: 0.1623 - val_loss: 3084.9161 - val_acc: 0.1814\n",
      "Epoch 4/100\n",
      "42735/42735 [==============================] - 34s 803us/step - loss: 3127.4541 - acc: 0.1590 - val_loss: 3083.2418 - val_acc: 0.1758\n",
      "Epoch 5/100\n",
      "42735/42735 [==============================] - 34s 803us/step - loss: 3123.4109 - acc: 0.1549 - val_loss: 3078.0413 - val_acc: 0.1766\n",
      "Epoch 6/100\n",
      "42735/42735 [==============================] - 34s 802us/step - loss: 3120.0459 - acc: 0.1528 - val_loss: 3075.6535 - val_acc: 0.1694\n",
      "Epoch 7/100\n",
      "42735/42735 [==============================] - 34s 801us/step - loss: 3118.5626 - acc: 0.1510 - val_loss: 3075.3361 - val_acc: 0.1755\n",
      "Epoch 8/100\n",
      "42735/42735 [==============================] - 34s 804us/step - loss: 3117.5692 - acc: 0.1543 - val_loss: 3074.1289 - val_acc: 0.1735\n",
      "Epoch 9/100\n",
      "42735/42735 [==============================] - 34s 804us/step - loss: 3116.9125 - acc: 0.1524 - val_loss: 3073.9286 - val_acc: 0.1691\n",
      "Epoch 10/100\n",
      "42735/42735 [==============================] - 34s 802us/step - loss: 3116.3013 - acc: 0.1510 - val_loss: 3074.8394 - val_acc: 0.1739\n"
     ]
    }
   ],
   "source": [
    "model5 = DeepCollab(batch_size=128, hidden_layers=5, user_features=False, nodes=2048)\n",
    "model5.fit(train_ratings_noisy, train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model5.autoencoder.save('models/autoencoder_1stmethod.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Attempt at 'noise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_ratings = pd.read_csv('data/unprocessed/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_features = pd.read_csv('data/user_features_final.csv')\n",
    "users = user_features['user_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_users, test_users = train_test_split(users, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_users = pd.read_csv('data/train_ratings_set.csv')\n",
    "train_data_users = data_users[data_users['user_id'].isin(train_users)]\n",
    "test_data_users = data_users[data_users['user_id'].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_users.to_csv('data/backups/autoencoder_train.csv', index=False)\n",
    "test_data_users.to_csv('data/backups/autoencoder_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_users = train_data_users.pivot(index='user_id', columns='book_id')\n",
    "train_data_users.fillna(0, inplace=True)\n",
    "train_data_users = np.asarray(train_data_users)\n",
    "train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised_train_data_users = full_ratings[full_ratings['user_id'].isin(train_users)]\n",
    "denoised_train_data_users = denoised_train_data_users.pivot(index='user_id', columns='book_id')\n",
    "denoised_train_data_users.fillna(0, inplace=True)\n",
    "denoised_train_data_users = np.asarray(denoised_train_data_users)\n",
    "denoised_train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 120,501,024\n",
      "Trainable params: 120,501,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 395us/step - loss: 3297.2810 - acc: 0.1651 - val_loss: 3221.1377 - val_acc: 0.1851\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 389us/step - loss: 3253.2290 - acc: 0.1486 - val_loss: 3201.7023 - val_acc: 0.1526\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 394us/step - loss: 3238.8027 - acc: 0.1363 - val_loss: 3194.3691 - val_acc: 0.1453\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 390us/step - loss: 3231.0492 - acc: 0.1368 - val_loss: 3194.7767 - val_acc: 0.1642\n"
     ]
    }
   ],
   "source": [
    "model = DeepCollab(batch_size=128, hidden_layers=1, user_features=False)\n",
    "model.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,551,136\n",
      "Trainable params: 121,551,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 396us/step - loss: 3349.3614 - acc: 0.1269 - val_loss: 3286.1279 - val_acc: 0.1880\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 395us/step - loss: 3308.9621 - acc: 0.1751 - val_loss: 3266.8313 - val_acc: 0.1933\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 389us/step - loss: 3291.7457 - acc: 0.1655 - val_loss: 3262.3881 - val_acc: 0.1920\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 391us/step - loss: 3286.7746 - acc: 0.1680 - val_loss: 3258.7773 - val_acc: 0.1883\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 391us/step - loss: 3281.8157 - acc: 0.1635 - val_loss: 3255.1993 - val_acc: 0.1844\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 391us/step - loss: 3277.9733 - acc: 0.1603 - val_loss: 3252.1937 - val_acc: 0.1829\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 3275.5323 - acc: 0.1573 - val_loss: 3252.1099 - val_acc: 0.1770\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 12s 389us/step - loss: 3272.9893 - acc: 0.1556 - val_loss: 3249.8914 - val_acc: 0.1772\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 3271.6201 - acc: 0.1573 - val_loss: 3249.0795 - val_acc: 0.1788\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 12s 394us/step - loss: 3268.4644 - acc: 0.1538 - val_loss: 3247.2613 - val_acc: 0.1760\n",
      "Epoch 11/100\n",
      "29914/29914 [==============================] - 12s 392us/step - loss: 3266.4041 - acc: 0.1535 - val_loss: 3244.5517 - val_acc: 0.1769\n",
      "Epoch 12/100\n",
      "29914/29914 [==============================] - 12s 391us/step - loss: 3263.7520 - acc: 0.1555 - val_loss: 3243.1799 - val_acc: 0.1734\n",
      "Epoch 13/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 3260.8866 - acc: 0.1515 - val_loss: 3240.1727 - val_acc: 0.1748\n",
      "Epoch 14/100\n",
      "29914/29914 [==============================] - 12s 396us/step - loss: 3259.3988 - acc: 0.1532 - val_loss: 3239.5943 - val_acc: 0.1726\n",
      "Epoch 15/100\n",
      "29914/29914 [==============================] - 12s 396us/step - loss: 3257.3164 - acc: 0.1489 - val_loss: 3238.8582 - val_acc: 0.1685\n",
      "Epoch 16/100\n",
      "29914/29914 [==============================] - 12s 389us/step - loss: 3256.3978 - acc: 0.1493 - val_loss: 3237.3699 - val_acc: 0.1719\n",
      "Epoch 17/100\n",
      "29914/29914 [==============================] - 12s 391us/step - loss: 3256.1819 - acc: 0.1496 - val_loss: 3237.0106 - val_acc: 0.1683\n",
      "Epoch 18/100\n",
      "29914/29914 [==============================] - 12s 392us/step - loss: 3252.5267 - acc: 0.1444 - val_loss: 3237.6189 - val_acc: 0.1706\n"
     ]
    }
   ],
   "source": [
    "model2 = DeepCollab(batch_size=128, hidden_layers=3, user_features=False)\n",
    "model2.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,814,048\n",
      "Trainable params: 121,814,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 400us/step - loss: 2670.3140 - acc: 0.0886 - val_loss: 2421.8886 - val_acc: 0.1285\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 394us/step - loss: 2449.9063 - acc: 0.1426 - val_loss: 2369.3697 - val_acc: 0.1670\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 397us/step - loss: 2406.6175 - acc: 0.1576 - val_loss: 2338.8738 - val_acc: 0.1780\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 2379.9273 - acc: 0.1568 - val_loss: 2330.2397 - val_acc: 0.1749\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 397us/step - loss: 2368.5003 - acc: 0.1564 - val_loss: 2329.4035 - val_acc: 0.1753\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 399us/step - loss: 2351.8230 - acc: 0.1582 - val_loss: 2314.7683 - val_acc: 0.1808\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 2342.7840 - acc: 0.1620 - val_loss: 2299.4517 - val_acc: 0.1781\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 12s 397us/step - loss: 2332.6955 - acc: 0.1602 - val_loss: 2301.6238 - val_acc: 0.1784\n"
     ]
    }
   ],
   "source": [
    "model3 = DeepCollab(batch_size=128, hidden_layers=5, user_features=False)\n",
    "model3.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.autoencoder.save('models/autoencoder_full_noise_5layers.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voldemort/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_users = data_users[data_users['user_id'].isin(train_users)]\n",
    "\n",
    "train_data_users['rating'] = train_data_users.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "train_data_users = train_data_users.pivot(index='user_id', columns='book_id')\n",
    "train_data_users.fillna(0, inplace=True)\n",
    "train_data_users = np.asarray(train_data_users)\n",
    "train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voldemort/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised_train_data_users = full_ratings[full_ratings['user_id'].isin(train_users)]\n",
    "denoised_train_data_users['rating'] = denoised_train_data_users.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)\n",
    "denoised_train_data_users = denoised_train_data_users.pivot(index='user_id', columns='book_id')\n",
    "denoised_train_data_users.fillna(0, inplace=True)\n",
    "denoised_train_data_users = np.asarray(denoised_train_data_users)\n",
    "denoised_train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 120,501,024\n",
      "Trainable params: 120,501,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 390us/step - loss: 459.1833 - acc: 0.0682 - val_loss: 448.3762 - val_acc: 0.0558\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 389us/step - loss: 438.9374 - acc: 0.0933 - val_loss: 442.6482 - val_acc: 0.1056\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 385us/step - loss: 432.4222 - acc: 0.1097 - val_loss: 439.3085 - val_acc: 0.1141\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 385us/step - loss: 428.3214 - acc: 0.1181 - val_loss: 437.9451 - val_acc: 0.1225\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 386us/step - loss: 425.3154 - acc: 0.1238 - val_loss: 435.0158 - val_acc: 0.1231\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 388us/step - loss: 422.2267 - acc: 0.1240 - val_loss: 433.8437 - val_acc: 0.1317\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 12s 390us/step - loss: 419.8214 - acc: 0.1314 - val_loss: 432.3677 - val_acc: 0.1383\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 12s 391us/step - loss: 418.0358 - acc: 0.1345 - val_loss: 431.4048 - val_acc: 0.1392\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 12s 386us/step - loss: 416.6127 - acc: 0.1365 - val_loss: 430.9331 - val_acc: 0.1396\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 12s 387us/step - loss: 414.8229 - acc: 0.1384 - val_loss: 429.8576 - val_acc: 0.1400\n",
      "Epoch 11/100\n",
      "29914/29914 [==============================] - 12s 387us/step - loss: 413.4696 - acc: 0.1373 - val_loss: 429.8224 - val_acc: 0.1460\n",
      "Epoch 12/100\n",
      "29914/29914 [==============================] - 12s 390us/step - loss: 412.4587 - acc: 0.1370 - val_loss: 429.0801 - val_acc: 0.1364\n",
      "Epoch 13/100\n",
      "29914/29914 [==============================] - 12s 389us/step - loss: 411.4150 - acc: 0.1367 - val_loss: 429.1650 - val_acc: 0.1455\n"
     ]
    }
   ],
   "source": [
    "model = DeepCollab(batch_size=128, hidden_layers=1, user_features=False)\n",
    "model.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,551,136\n",
      "Trainable params: 121,551,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 394us/step - loss: 458.8051 - acc: 0.0893 - val_loss: 447.0984 - val_acc: 0.1431\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 394us/step - loss: 432.1111 - acc: 0.1280 - val_loss: 433.0866 - val_acc: 0.1693\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 390us/step - loss: 423.7155 - acc: 0.1460 - val_loss: 427.8222 - val_acc: 0.1770\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 390us/step - loss: 417.6842 - acc: 0.1581 - val_loss: 423.3665 - val_acc: 0.1872\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 414.1268 - acc: 0.1665 - val_loss: 420.8984 - val_acc: 0.1916\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 411.0579 - acc: 0.1772 - val_loss: 418.9889 - val_acc: 0.1897\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 408.8484 - acc: 0.1789 - val_loss: 417.8302 - val_acc: 0.1978\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 12s 392us/step - loss: 406.8904 - acc: 0.1820 - val_loss: 417.1323 - val_acc: 0.2028\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 405.0961 - acc: 0.1849 - val_loss: 415.6692 - val_acc: 0.1923\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 404.0779 - acc: 0.1846 - val_loss: 415.4371 - val_acc: 0.2095\n",
      "Epoch 11/100\n",
      "29914/29914 [==============================] - 12s 392us/step - loss: 403.3613 - acc: 0.1873 - val_loss: 414.6961 - val_acc: 0.2134\n",
      "Epoch 12/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 401.6810 - acc: 0.1873 - val_loss: 415.1192 - val_acc: 0.2103\n"
     ]
    }
   ],
   "source": [
    "model2 = DeepCollab(batch_size=128, hidden_layers=3, user_features=False)\n",
    "model2.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,814,048\n",
      "Trainable params: 121,814,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 401us/step - loss: 459.3127 - acc: 0.0290 - val_loss: 441.4307 - val_acc: 0.0540\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 432.9543 - acc: 0.1569 - val_loss: 434.6152 - val_acc: 0.2138\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 423.2152 - acc: 0.2183 - val_loss: 425.2357 - val_acc: 0.2551\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 399us/step - loss: 416.5870 - acc: 0.2199 - val_loss: 422.1041 - val_acc: 0.2475\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 400us/step - loss: 413.9770 - acc: 0.2219 - val_loss: 418.4160 - val_acc: 0.2535\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 410.2627 - acc: 0.2213 - val_loss: 415.5934 - val_acc: 0.2554\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 12s 393us/step - loss: 408.2783 - acc: 0.2273 - val_loss: 414.7526 - val_acc: 0.2437\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 12s 399us/step - loss: 406.9840 - acc: 0.2203 - val_loss: 415.5638 - val_acc: 0.2425\n"
     ]
    }
   ],
   "source": [
    "model3 = DeepCollab(batch_size=128, hidden_layers=5, user_features=False)\n",
    "model3.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.autoencoder.save('models/autoencoder_5layers_128batch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_users.dump('data/backups/autoencoder_train_binary.csv')\n",
    "denoised_train_data_users.dump('data/backups/autoencoder_train_denoised_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_users = np.load('data/backups/autoencoder_train_binary.csv')\n",
    "denoised_train_data_users = np.load('data/backups/autoencoder_train_denoised_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,814,048\n",
      "Trainable params: 121,814,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 21s 715us/step - loss: 457.7000 - acc: 0.1466 - val_loss: 443.7068 - val_acc: 0.2169\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 432.3066 - acc: 0.2094 - val_loss: 432.5758 - val_acc: 0.2321\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 425.5011 - acc: 0.2134 - val_loss: 428.4914 - val_acc: 0.2450\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 421.4314 - acc: 0.2158 - val_loss: 423.8077 - val_acc: 0.2388\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 21s 706us/step - loss: 418.4475 - acc: 0.2195 - val_loss: 421.9428 - val_acc: 0.2519\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 414.4617 - acc: 0.2206 - val_loss: 420.5861 - val_acc: 0.2491\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 21s 704us/step - loss: 411.4252 - acc: 0.2165 - val_loss: 416.1974 - val_acc: 0.2474\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 409.1624 - acc: 0.2136 - val_loss: 415.7889 - val_acc: 0.2432\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 21s 704us/step - loss: 407.2802 - acc: 0.2188 - val_loss: 413.7895 - val_acc: 0.2455\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 21s 705us/step - loss: 404.9904 - acc: 0.2152 - val_loss: 412.0845 - val_acc: 0.2444\n",
      "Epoch 11/100\n",
      "29914/29914 [==============================] - 21s 704us/step - loss: 403.5021 - acc: 0.2095 - val_loss: 411.7538 - val_acc: 0.2304\n",
      "Epoch 12/100\n",
      "29914/29914 [==============================] - 21s 704us/step - loss: 401.9401 - acc: 0.2068 - val_loss: 411.4620 - val_acc: 0.2320\n",
      "Epoch 13/100\n",
      "29914/29914 [==============================] - 21s 706us/step - loss: 400.7282 - acc: 0.2070 - val_loss: 410.2923 - val_acc: 0.2363\n",
      "Epoch 14/100\n",
      "29914/29914 [==============================] - 21s 703us/step - loss: 400.2936 - acc: 0.2049 - val_loss: 409.9349 - val_acc: 0.2261\n",
      "Epoch 15/100\n",
      "29914/29914 [==============================] - 21s 705us/step - loss: 399.1970 - acc: 0.2022 - val_loss: 409.4957 - val_acc: 0.2317\n",
      "Epoch 16/100\n",
      "29914/29914 [==============================] - 21s 700us/step - loss: 398.4281 - acc: 0.1996 - val_loss: 410.3933 - val_acc: 0.2296\n"
     ]
    }
   ],
   "source": [
    "model4 = DeepCollab(batch_size=64, hidden_layers=5, user_features=False)\n",
    "model4.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10000)             100010000 \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10000)             10250000  \n",
      "=================================================================\n",
      "Total params: 121,814,048\n",
      "Trainable params: 121,814,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 8s 265us/step - loss: 467.2585 - acc: 0.0509 - val_loss: 445.6084 - val_acc: 0.1879\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 8s 261us/step - loss: 433.7063 - acc: 0.1770 - val_loss: 431.6677 - val_acc: 0.1982\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 8s 263us/step - loss: 423.4908 - acc: 0.1790 - val_loss: 423.5295 - val_acc: 0.2135\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 8s 262us/step - loss: 417.5744 - acc: 0.1995 - val_loss: 420.4651 - val_acc: 0.2272\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 8s 261us/step - loss: 413.1279 - acc: 0.2085 - val_loss: 417.1684 - val_acc: 0.2316\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 8s 261us/step - loss: 409.9814 - acc: 0.2071 - val_loss: 414.5389 - val_acc: 0.2385\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 8s 265us/step - loss: 407.4847 - acc: 0.2076 - val_loss: 413.4007 - val_acc: 0.2371\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 8s 261us/step - loss: 405.5616 - acc: 0.2098 - val_loss: 411.4926 - val_acc: 0.2389\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 7s 249us/step - loss: 403.6068 - acc: 0.2114 - val_loss: 410.8215 - val_acc: 0.2357\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 8s 260us/step - loss: 402.5377 - acc: 0.2088 - val_loss: 410.3382 - val_acc: 0.2321\n",
      "Epoch 11/100\n",
      "29914/29914 [==============================] - 8s 259us/step - loss: 401.0618 - acc: 0.2064 - val_loss: 410.4008 - val_acc: 0.2321\n"
     ]
    }
   ],
   "source": [
    "model4 = DeepCollab(batch_size=256, hidden_layers=5, user_features=False)\n",
    "model4.fit(train_data_users, denoised_train_data_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Inputs (CDAE)\n",
    "## Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                                        ...   \\\n",
       "book_id  1     2     3     4     5     6     7     8     9     10     ...    \n",
       "user_id                                                               ...    \n",
       "6          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "7          NaN   NaN   NaN   NaN   3.0   NaN   NaN   2.0   NaN   NaN  ...    \n",
       "8          NaN   NaN   NaN   3.0   3.0   NaN   NaN   NaN   NaN   1.0  ...    \n",
       "9          4.0   4.0   4.0   NaN   NaN   NaN   NaN   NaN   1.0   5.0  ...    \n",
       "10         NaN   NaN   NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "\n",
       "                                                                     \n",
       "book_id 9991  9992  9993  9994  9995  9996  9997  9998  9999  10000  \n",
       "user_id                                                              \n",
       "6         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "7         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "8         1.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "9         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "10        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('data/backups/autoencoder_train.csv', header=0)\n",
    "temp = temp.pivot(index='user_id', columns='book_id')\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_users = temp.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_features = pd.read_csv('data/user_features_final.csv')\n",
    "train_user_features = user_features[user_features['user_id'].isin(list(train_users))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 27)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.195982</td>\n",
       "      <td>0.01082</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.06773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006.0</td>\n",
       "      <td>3.784615</td>\n",
       "      <td>0.195982</td>\n",
       "      <td>0.01082</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.06773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.195982</td>\n",
       "      <td>0.01082</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.06773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3006.0</td>\n",
       "      <td>3.819444</td>\n",
       "      <td>0.195982</td>\n",
       "      <td>0.01082</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.06773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10006.0</td>\n",
       "      <td>3.739726</td>\n",
       "      <td>0.195982</td>\n",
       "      <td>0.01082</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.06773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  avg_rating         0        1         2         3        4  \\\n",
       "0       6.0    4.285714  0.195982  0.01082  0.008561  0.007327  0.03029   \n",
       "1    1006.0    3.784615  0.195982  0.01082  0.008561  0.007327  0.03029   \n",
       "2    2006.0    4.100000  0.195982  0.01082  0.008561  0.007327  0.03029   \n",
       "3    3006.0    3.819444  0.195982  0.01082  0.008561  0.007327  0.03029   \n",
       "10  10006.0    3.739726  0.195982  0.01082  0.008561  0.007327  0.03029   \n",
       "\n",
       "           5         6         7   ...           15   16        17        18  \\\n",
       "0   0.032636  0.028151  0.012982   ...     0.001723  0.0  0.011177  0.020266   \n",
       "1   0.032636  0.028151  0.012982   ...     0.001723  0.0  0.011177  0.020266   \n",
       "2   0.032636  0.028151  0.012982   ...     0.001723  0.0  0.011177  0.020266   \n",
       "3   0.032636  0.028151  0.012982   ...     0.001723  0.0  0.011177  0.020266   \n",
       "10  0.032636  0.028151  0.012982   ...     0.001723  0.0  0.011177  0.020266   \n",
       "\n",
       "          19        20        21        22        23       24  \n",
       "0   0.015214  0.020975  0.041102  0.010981  0.012653  0.06773  \n",
       "1   0.015214  0.020975  0.041102  0.010981  0.012653  0.06773  \n",
       "2   0.015214  0.020975  0.041102  0.010981  0.012653  0.06773  \n",
       "3   0.015214  0.020975  0.041102  0.010981  0.012653  0.06773  \n",
       "10  0.015214  0.020975  0.041102  0.010981  0.012653  0.06773  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_user_features['avg_rating'] = train_user_features.apply(lambda x: x['avg_rating']/5, axis=1)\n",
    "train_user_features.drop('user_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_user_features = np.asarray(train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_users = train_data_users.pivot(index='user_id', columns='book_id')\n",
    "train_data_users.fillna(0, inplace=True)\n",
    "train_data_users = np.asarray(train_data_users)\n",
    "train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised_train_data_users = full_ratings[full_ratings['user_id'].isin(train_users)]\n",
    "denoised_train_data_users = denoised_train_data_users.pivot(index='user_id', columns='book_id')\n",
    "denoised_train_data_users.fillna(0, inplace=True)\n",
    "denoised_train_data_users = np.asarray(denoised_train_data_users)\n",
    "denoised_train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 10000)        100010000   input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 26)           702         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 10026)        0           dense_22[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1024)         10267648    concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 512)          524800      dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 256)          131328      dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 512)          131584      dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1024)         525312      dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 10000)        10250000    dense_28[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 121,841,374\n",
      "Trainable params: 121,841,374\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 402us/step - loss: 458.4680 - acc: 0.0906 - val_loss: 440.6244 - val_acc: 0.2153\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 430.0823 - acc: 0.1937 - val_loss: 426.9790 - val_acc: 0.2340\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 399us/step - loss: 421.8591 - acc: 0.2070 - val_loss: 423.1039 - val_acc: 0.2333\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 403us/step - loss: 416.7810 - acc: 0.2122 - val_loss: 419.1058 - val_acc: 0.2488\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 401us/step - loss: 413.0068 - acc: 0.2139 - val_loss: 416.4164 - val_acc: 0.2413\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 395us/step - loss: 409.1352 - acc: 0.2144 - val_loss: 414.0648 - val_acc: 0.2337\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 406.3142 - acc: 0.2107 - val_loss: 413.6301 - val_acc: 0.2282\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 404.5124 - acc: 0.2069 - val_loss: 412.1488 - val_acc: 0.2325\n",
      "Epoch 9/100\n",
      "29914/29914 [==============================] - 12s 402us/step - loss: 402.9518 - acc: 0.2093 - val_loss: 411.5722 - val_acc: 0.2357\n",
      "Epoch 10/100\n",
      "29914/29914 [==============================] - 12s 400us/step - loss: 402.1235 - acc: 0.2060 - val_loss: 410.5949 - val_acc: 0.2269\n",
      "Epoch 11/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 400.4909 - acc: 0.1974 - val_loss: 410.8767 - val_acc: 0.2228\n"
     ]
    }
   ],
   "source": [
    "model = DeepCollab(batch_size=128, hidden_layers=5, user_features=True)\n",
    "model.fit(train_data_users, denoised_train_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 10000)        100010000   input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 26)           702         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 10026)        0           dense_30[0][0]                   \n",
      "                                                                 dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 1024)         10267648    concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 10000)        10250000    dense_32[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 120,528,350\n",
      "Trainable params: 120,528,350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 394us/step - loss: 460.2260 - acc: 0.1135 - val_loss: 445.5083 - val_acc: 0.1138\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 395us/step - loss: 438.0483 - acc: 0.1206 - val_loss: 440.9040 - val_acc: 0.1413\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 396us/step - loss: 432.4774 - acc: 0.1380 - val_loss: 439.9680 - val_acc: 0.1562\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 392us/step - loss: 428.6395 - acc: 0.1473 - val_loss: 435.8936 - val_acc: 0.1675\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 397us/step - loss: 425.9075 - acc: 0.1589 - val_loss: 435.4981 - val_acc: 0.1774\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 423.7820 - acc: 0.1609 - val_loss: 435.6331 - val_acc: 0.1622\n"
     ]
    }
   ],
   "source": [
    "model1 = DeepCollab(batch_size=128, hidden_layers=1, user_features=True)\n",
    "model1.fit(train_data_users, denoised_train_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 10000)        100010000   input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 26)           702         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 10026)        0           dense_34[0][0]                   \n",
      "                                                                 dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 1024)         10267648    concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 512)          524800      dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 1024)         525312      dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 10000)        10250000    dense_38[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 121,578,462\n",
      "Trainable params: 121,578,462\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 399us/step - loss: 460.0007 - acc: 0.0584 - val_loss: 441.7853 - val_acc: 0.0624\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 398us/step - loss: 434.2164 - acc: 0.0795 - val_loss: 434.7596 - val_acc: 0.0734\n",
      "Epoch 3/100\n",
      "29914/29914 [==============================] - 12s 402us/step - loss: 425.3801 - acc: 0.1074 - val_loss: 429.6458 - val_acc: 0.1099\n",
      "Epoch 4/100\n",
      "29914/29914 [==============================] - 12s 399us/step - loss: 420.4492 - acc: 0.1199 - val_loss: 425.0374 - val_acc: 0.1257\n",
      "Epoch 5/100\n",
      "29914/29914 [==============================] - 12s 392us/step - loss: 416.7123 - acc: 0.1324 - val_loss: 423.6812 - val_acc: 0.1349\n",
      "Epoch 6/100\n",
      "29914/29914 [==============================] - 12s 400us/step - loss: 413.5308 - acc: 0.1518 - val_loss: 420.7442 - val_acc: 0.1639\n",
      "Epoch 7/100\n",
      "29914/29914 [==============================] - 12s 395us/step - loss: 411.6556 - acc: 0.1534 - val_loss: 420.0326 - val_acc: 0.1641\n",
      "Epoch 8/100\n",
      "29914/29914 [==============================] - 12s 399us/step - loss: 409.5548 - acc: 0.1586 - val_loss: 420.1661 - val_acc: 0.1594\n"
     ]
    }
   ],
   "source": [
    "model2 = DeepCollab(batch_size=128, hidden_layers=3, user_features=True)\n",
    "model2.fit(train_data_users, denoised_train_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.autoencoder.save('models/autoencoder_userfeatures_5layers.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_user_features.dump('data/backups/train_user_features_autoencoder.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_users = pd.read_csv('data/backups/autoencoder_train.csv', header=0)\n",
    "train_data_users['rating'] = train_data_users.apply(lambda x: train_data_users['rating']/5, axis=1)\n",
    "train_data_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_users = list(set(train_data_users['user_id'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_user_features = np.load('data/backups/train_user_features_autoencoder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_users = train_data_users.pivot(index='user_id', columns='book_id')\n",
    "train_data_users.fillna(0, inplace=True)\n",
    "train_data_users = np.asarray(train_data_users)\n",
    "train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ratings = pd.read_csv('data/unprocessed/ratings.csv', header=0)\n",
    "denoised_train_data_users = full_ratings[full_ratings['user_id'].isin(train_users)]\n",
    "\n",
    "train_data_users['rating'] = train_data_users.apply(lambda x: train_data_users['rating']/5, axis=1)\n",
    "denoised_train_data_users = denoised_train_data_users.pivot(index='user_id', columns='book_id')\n",
    "denoised_train_data_users.fillna(0, inplace=True)\n",
    "denoised_train_data_users = np.asarray(denoised_train_data_users)\n",
    "denoised_train_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10000)        100010000   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 26)           702         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10026)        0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         10267648    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          524800      dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          131328      dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 512)          131584      dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1024)         525312      dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10000)        10250000    dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 121,841,374\n",
      "Trainable params: 121,841,374\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 12s 412us/step - loss: 4958.9704 - acc: 0.0313 - val_loss: 4836.5623 - val_acc: 0.0190\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 12s 400us/step - loss: 4968.9537 - acc: 0.0217 - val_loss: 4836.5623 - val_acc: 0.0190\n"
     ]
    }
   ],
   "source": [
    "model = DeepCollab(batch_size=128, hidden_layers=5, user_features=True)\n",
    "model.fit(train_data_users, denoised_train_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10000)        100010000   input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 26)           702         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 10026)        0           dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1024)         10267648    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 512)          524800      dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          131328      dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 512)          131584      dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1024)         525312      dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 10000)        10250000    dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 121,841,374\n",
      "Trainable params: 121,841,374\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 21s 716us/step - loss: 4955.8168 - acc: 0.1452 - val_loss: 4825.0992 - val_acc: 0.1619\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 21s 712us/step - loss: 4960.2418 - acc: 0.1455 - val_loss: 4825.0992 - val_acc: 0.1619\n"
     ]
    }
   ],
   "source": [
    "model3 = DeepCollab(batch_size=64, hidden_layers=5, user_features=True)\n",
    "model3.fit(train_data_users, denoised_train_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 10000)        100010000   input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 26)           702         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 10026)        0           dense_17[0][0]                   \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1024)         10267648    concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 512)          524800      dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 256)          131328      dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 512)          131584      dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1024)         525312      dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 10000)        10250000    dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 121,841,374\n",
      "Trainable params: 121,841,374\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 39s 1ms/step - loss: 4958.1274 - acc: 0.1453 - val_loss: 4825.0992 - val_acc: 0.1619\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 39s 1ms/step - loss: 4960.2418 - acc: 0.1455 - val_loss: 4825.0992 - val_acc: 0.1619\n"
     ]
    }
   ],
   "source": [
    "model4 = DeepCollab(batch_size=32, hidden_layers=5, user_features=True)\n",
    "model4.fit(train_data_users, denoised_train_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 10000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 10000)        100010000   input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 26)           702         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 10026)        0           dense_25[0][0]                   \n",
      "                                                                 dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 2048)         20535296    concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1024)         2098176     dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 512)          524800      dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1024)         525312      dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 2048)         2099200     dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 10000)        20490000    dense_31[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 146,283,486\n",
      "Trainable params: 146,283,486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 29914 samples, validate on 7479 samples\n",
      "Epoch 1/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 4958.5980 - acc: 0.1078 - val_loss: 4824.4828 - val_acc: 0.1433\n",
      "Epoch 2/100\n",
      "29914/29914 [==============================] - 46s 2ms/step - loss: 4960.8194 - acc: 0.1080 - val_loss: 4824.4828 - val_acc: 0.1433\n"
     ]
    }
   ],
   "source": [
    "model5 = DeepCollab(batch_size=32, hidden_layers=5, user_features=True, nodes=2048)\n",
    "model5.fit(train_data_users, denoised_train_data_users, train_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37393, 26)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from keras.layers import Dense, Input, Concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "class DeepCollab:\n",
    "    def __init__(self, batch_size, hidden_layers, user_features, epochs=100, earlystopping=True, nodes=1024):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.user_features = user_features\n",
    "        self.epochs = epochs\n",
    "        self.earlystopping = earlystopping\n",
    "        self.nodes = nodes\n",
    "\n",
    "        # Models\n",
    "        self.autoencoder = None\n",
    "        \n",
    "\n",
    "    def fit(self, y, y_noisy, features=None):\n",
    "        tensorboard = TensorBoard(log_dir=\"logs/collab/{}\".format(time()))\n",
    "       \n",
    "        # Input\n",
    "        input = Input(shape=(y.shape[1],))\n",
    "        # Encode\n",
    "        encoded = Dense(y.shape[1], activation='relu')(input)\n",
    "\n",
    "        if self.user_features:\n",
    "            user_input = Input(shape=(features.shape[1],))\n",
    "            user_nodes = Dense(features.shape[1], activation='relu')(user_input)\n",
    "            merged = Concatenate()([encoded, user_nodes])\n",
    "\n",
    "            # Hidden Layer\n",
    "            hidden = Dense(self.nodes, activation='relu')(merged)\n",
    "\n",
    "        else:\n",
    "            # Hidden Layer\n",
    "            hidden = Dense(self.nodes, activation='relu')(encoded)\n",
    "\n",
    "        if self.hidden_layers == 3:\n",
    "            hidden = Dense(int(self.nodes/2), activation='relu')(hidden)\n",
    "            hidden = Dense(self.nodes, activation='relu')(hidden)\n",
    "        elif self.hidden_layers == 5:\n",
    "            hidden = Dense(int(self.nodes/2), activation='relu')(hidden)\n",
    "            hidden = Dense(int(self.nodes/4), activation='relu')(hidden)\n",
    "            hidden = Dense(int(self.nodes/2), activation='relu')(hidden)\n",
    "            hidden = Dense(self.nodes, activation='relu')(hidden)\n",
    "\n",
    "        # Decode\n",
    "        decoded = Dense(y.shape[1], activation='softmax', bias_initializer='ones')(hidden)\n",
    "\n",
    "        if self.user_features:\n",
    "            self.autoencoder = Model([input, user_input], decoded)\n",
    "            \n",
    "        else:\n",
    "            self.autoencoder = Model(input, decoded)\n",
    "\n",
    "        self.autoencoder.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        self.autoencoder.summary()\n",
    "\n",
    "        if self.earlystopping:\n",
    "            callbacks = [EarlyStopping(), tensorboard]\n",
    "        else:\n",
    "            callbacks = [tensorboard]\n",
    "            \n",
    "        if self.user_features:\n",
    "\n",
    "            self.autoencoder.fit([y_noisy, features], y,\n",
    "                                 epochs=self.epochs,\n",
    "                                 batch_size=self.batch_size,\n",
    "                                 validation_split=0.2,\n",
    "                                 callbacks=callbacks)\n",
    "\n",
    "        else:\n",
    "\n",
    "            self.autoencoder.fit(y_noisy, y,\n",
    "                                 epochs=self.epochs,\n",
    "                                 batch_size=self.batch_size,\n",
    "                                 validation_split=0.2,\n",
    "                                 callbacks=callbacks)\n",
    "\n",
    "    def predict(self, y_noisy, features):\n",
    "\n",
    "        if self.user_features:\n",
    "            predictions = self.autoencoder.predict([y_noisy, features], verbose=1)\n",
    "        else:\n",
    "            predictions = self.autoencoder.predict(y_noisy, verbose=1)\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16026, 10000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_users = pd.read_csv('data/backups/autoencoder_test.csv', header=0)\n",
    "test_users = list(set(test_data_users['user_id'].tolist()))\n",
    "test_data_users = test_data_users.pivot(index='user_id', columns='book_id')\n",
    "test_data_users.fillna(0, inplace=True)\n",
    "test_data_users = np.asarray(test_data_users)\n",
    "test_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16026, 10000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised_test_data_users = full_ratings[full_ratings['user_id'].isin(test_users)]\n",
    "denoised_test_data_users = denoised_test_data_users.pivot(index='user_id', columns='book_id')\n",
    "denoised_test_data_users.fillna(0, inplace=True)\n",
    "denoised_test_data_users = np.asarray(denoised_test_data_users)\n",
    "denoised_test_data_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16026, 26)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features = pd.read_csv('data/user_features_final.csv')\n",
    "test_user_features = user_features[user_features['user_id'].isin(list(test_users))].copy()\n",
    "test_user_features['avg_rating'] = test_user_features.apply(lambda x: x['avg_rating']/5, axis=1)\n",
    "test_user_features.drop('user_id', axis=1, inplace=True)\n",
    "test_user_features = np.asarray(test_user_features)\n",
    "test_user_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16026/16026 [==============================] - 3s 215us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model3.predict(test_data_users, test_user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16026, 10000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4881435. , 5282606.5, 2000445.1, ...,       0. ,       0. ,\n",
       "             0. ], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ratings = pd.read_csv('data/backups/autoencoder_test.csv', header=0)\n",
    "full_ratings = pd.read_csv('data/unprocessed/ratings.csv', header=0)\n",
    "\n",
    "pred_dfs = []\n",
    "\n",
    "for index, user in enumerate(test_users):\n",
    "    train_books = test_ratings[test_ratings['user_id'] == user]['book_id'].tolist()\n",
    "    all_books = full_ratings[full_ratings['user_id'] == user]['book_id'].tolist()\n",
    "    test_books = [book for book in all_books if book not in train_books]\n",
    "    idx = [b + 1 for b in test_books]\n",
    "    test_book_ratings = full_ratings[full_ratings['book_id'] == user.isin(test_books)]['rating'].tolist()\n",
    "    raw_predictions = predictions[index]\n",
    "    raw_predictions = raw_predictions[idx]\n",
    "    \n",
    "    raw_filtered_predictions = [rating for ]\n",
    "    df = pd.DataFrame({'book_id': test_books, \n",
    "                       'rating': test_book_ratings,\n",
    "                       ''\n",
    "                       \n",
    "                       'pred_proba': list(raw_predictions[index].values())})\n",
    "    df['user_id'] = user\n",
    "    pred_dfs.append(df)\n",
    "    \n",
    "predictions = pd.concat(pred_dfs, ignore_index=True)\n",
    "\n",
    "evaluate_df = test_ratings.merge(predictions, on=['user_id', 'book_id'], how='left')\n",
    "evaluate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cold Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cold_start_features = np.zeros((1, 26))\n",
    "cold_start_ratings = np.zeros((1, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 26)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_start_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "cold_start = model3.predict(cold_start_ratings, cold_start_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[355256.53, 366768.  , 221019.7 , ...,      0.  ,      0.  ,\n",
       "             0.  ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cold_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cold_start.dump('data/backups/cold_start_5star_cdae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
