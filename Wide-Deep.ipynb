{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voldemort/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from keras.layers import Dense, Dropout, Input, Concatenate, Add, Dot\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from recsys.wide_deep import WideDeep\n",
    "import recsys.evaluate as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratings = pd.read_csv('data/train_ratings_set.csv')\n",
    "book_features = pd.read_csv('data/books_with_latent_features.csv')\n",
    "user_features = pd.read_csv('data/user_features_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36210</td>\n",
       "      <td>687</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1509</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42833</td>\n",
       "      <td>3128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39774</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28108</td>\n",
       "      <td>1120</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0    36210      687       2\n",
       "1        8     1509       1\n",
       "2    42833     3128       4\n",
       "3    39774       27       3\n",
       "4    28108     1120       5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.151500</td>\n",
       "      <td>0.170121</td>\n",
       "      <td>1.327789</td>\n",
       "      <td>30.036789</td>\n",
       "      <td>29.098997</td>\n",
       "      <td>24.874634</td>\n",
       "      <td>9.851855</td>\n",
       "      <td>12.846534</td>\n",
       "      <td>19.219327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.436243</td>\n",
       "      <td>0.108104</td>\n",
       "      <td>1.720847</td>\n",
       "      <td>28.904534</td>\n",
       "      <td>28.250940</td>\n",
       "      <td>11.911526</td>\n",
       "      <td>11.176438</td>\n",
       "      <td>10.143953</td>\n",
       "      <td>15.538545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.881646</td>\n",
       "      <td>0.153207</td>\n",
       "      <td>-1.698765</td>\n",
       "      <td>24.229710</td>\n",
       "      <td>22.987143</td>\n",
       "      <td>15.037225</td>\n",
       "      <td>68.549476</td>\n",
       "      <td>44.633867</td>\n",
       "      <td>27.389823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.412777</td>\n",
       "      <td>-0.100498</td>\n",
       "      <td>0.974035</td>\n",
       "      <td>19.983656</td>\n",
       "      <td>19.554820</td>\n",
       "      <td>11.375772</td>\n",
       "      <td>8.904196</td>\n",
       "      <td>11.763752</td>\n",
       "      <td>15.251665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.04148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.021077</td>\n",
       "      <td>0.031681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7.510681</td>\n",
       "      <td>-0.297825</td>\n",
       "      <td>-0.440977</td>\n",
       "      <td>16.710904</td>\n",
       "      <td>16.174804</td>\n",
       "      <td>8.012977</td>\n",
       "      <td>12.793850</td>\n",
       "      <td>20.018253</td>\n",
       "      <td>20.833128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011253</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  books_count  original_publication_year  average_rating  \\\n",
       "0        1     1.151500                   0.170121        1.327789   \n",
       "1        2     2.436243                   0.108104        1.720847   \n",
       "2        3     0.881646                   0.153207       -1.698765   \n",
       "3        4     2.412777                  -0.100498        0.974035   \n",
       "4        5     7.510681                  -0.297825       -0.440977   \n",
       "\n",
       "   ratings_count  work_ratings_count  work_text_reviews_count  ratings_1  \\\n",
       "0      30.036789           29.098997                24.874634   9.851855   \n",
       "1      28.904534           28.250940                11.911526  11.176438   \n",
       "2      24.229710           22.987143                15.037225  68.549476   \n",
       "3      19.983656           19.554820                11.375772   8.904196   \n",
       "4      16.710904           16.174804                 8.012977  12.793850   \n",
       "\n",
       "   ratings_2  ratings_3    ...           15        16        17        18  \\\n",
       "0  12.846534  19.219327    ...     0.000000  0.000000  0.000000  0.000668   \n",
       "1  10.143953  15.538545    ...     0.000000  0.000000  0.000000  0.000000   \n",
       "2  44.633867  27.389823    ...     0.000000  0.000000  0.026678  0.000000   \n",
       "3  11.763752  15.251665    ...     0.002680  0.000000  0.000000  0.009918   \n",
       "4  20.018253  20.833128    ...     0.011253  0.000036  0.000000  0.000000   \n",
       "\n",
       "        19   20   21        22        23        24  \n",
       "0  0.00000  0.0  0.0  0.000000  0.009848  0.000000  \n",
       "1  0.00000  0.0  0.0  0.000000  0.000000  0.000000  \n",
       "2  0.00000  0.0  0.0  0.000000  0.007945  0.000000  \n",
       "3  0.04148  0.0  0.0  0.000847  0.021077  0.031681  \n",
       "4  0.00000  0.0  0.0  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.195982</td>\n",
       "      <td>0.01082</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.06773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006.0</td>\n",
       "      <td>3.784615</td>\n",
       "      <td>0.195982</td>\n",
       "      <td>0.01082</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.06773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.195982</td>\n",
       "      <td>0.01082</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.06773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3006.0</td>\n",
       "      <td>3.819444</td>\n",
       "      <td>0.195982</td>\n",
       "      <td>0.01082</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.06773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4006.0</td>\n",
       "      <td>3.317647</td>\n",
       "      <td>0.195982</td>\n",
       "      <td>0.01082</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.028151</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.06773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  avg_rating         0        1         2         3        4  \\\n",
       "0      6.0    4.285714  0.195982  0.01082  0.008561  0.007327  0.03029   \n",
       "1   1006.0    3.784615  0.195982  0.01082  0.008561  0.007327  0.03029   \n",
       "2   2006.0    4.100000  0.195982  0.01082  0.008561  0.007327  0.03029   \n",
       "3   3006.0    3.819444  0.195982  0.01082  0.008561  0.007327  0.03029   \n",
       "4   4006.0    3.317647  0.195982  0.01082  0.008561  0.007327  0.03029   \n",
       "\n",
       "          5         6         7   ...           15   16        17        18  \\\n",
       "0  0.032636  0.028151  0.012982   ...     0.001723  0.0  0.011177  0.020266   \n",
       "1  0.032636  0.028151  0.012982   ...     0.001723  0.0  0.011177  0.020266   \n",
       "2  0.032636  0.028151  0.012982   ...     0.001723  0.0  0.011177  0.020266   \n",
       "3  0.032636  0.028151  0.012982   ...     0.001723  0.0  0.011177  0.020266   \n",
       "4  0.032636  0.028151  0.012982   ...     0.001723  0.0  0.011177  0.020266   \n",
       "\n",
       "         19        20        21        22        23       24  \n",
       "0  0.015214  0.020975  0.041102  0.010981  0.012653  0.06773  \n",
       "1  0.015214  0.020975  0.041102  0.010981  0.012653  0.06773  \n",
       "2  0.015214  0.020975  0.041102  0.010981  0.012653  0.06773  \n",
       "3  0.015214  0.020975  0.041102  0.010981  0.012653  0.06773  \n",
       "4  0.015214  0.020975  0.041102  0.010981  0.012653  0.06773  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_features['user_id'] = user_features.apply(lambda x: int(x['user_id']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_ratings.merge(user_features, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.merge(book_features, how='left', on='book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>...</th>\n",
       "      <th>15_y</th>\n",
       "      <th>16_y</th>\n",
       "      <th>17_y</th>\n",
       "      <th>18_y</th>\n",
       "      <th>19_y</th>\n",
       "      <th>20_y</th>\n",
       "      <th>21_y</th>\n",
       "      <th>22_y</th>\n",
       "      <th>23_y</th>\n",
       "      <th>24_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36210</td>\n",
       "      <td>687</td>\n",
       "      <td>2</td>\n",
       "      <td>3.536232</td>\n",
       "      <td>0.202367</td>\n",
       "      <td>0.033538</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.035502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.009414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1509</td>\n",
       "      <td>1</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>0.199233</td>\n",
       "      <td>0.013608</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42833</td>\n",
       "      <td>3128</td>\n",
       "      <td>4</td>\n",
       "      <td>4.611940</td>\n",
       "      <td>0.196320</td>\n",
       "      <td>0.021527</td>\n",
       "      <td>0.007529</td>\n",
       "      <td>0.007994</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.030204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39774</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>3.523810</td>\n",
       "      <td>0.156639</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.051112</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.067711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28108</td>\n",
       "      <td>1120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.678571</td>\n",
       "      <td>0.189999</td>\n",
       "      <td>0.032203</td>\n",
       "      <td>0.093174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.004424</td>\n",
       "      <td>0.009140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating  avg_rating       0_x       1_x       2_x  \\\n",
       "0    36210      687       2    3.536232  0.202367  0.033538  0.001456   \n",
       "1        8     1509       1    3.421053  0.199233  0.013608  0.000536   \n",
       "2    42833     3128       4    4.611940  0.196320  0.021527  0.007529   \n",
       "3    39774       27       3    3.523810  0.156639  0.050961  0.051112   \n",
       "4    28108     1120       5    4.678571  0.189999  0.032203  0.093174   \n",
       "\n",
       "        3_x       4_x       5_x    ...         15_y      16_y      17_y  18_y  \\\n",
       "0  0.005575  0.006220  0.035502    ...     0.001187  0.001917  0.000825   0.0   \n",
       "1  0.003621  0.023440  0.005159    ...     0.000000  0.000000  0.000000   0.0   \n",
       "2  0.007994  0.014450  0.030204    ...     0.000000  0.000000  0.000000   0.0   \n",
       "3  0.004160  0.012483  0.067711    ...     0.000000  0.000000  0.008164   0.0   \n",
       "4  0.000000  0.000000  0.085931    ...     0.001789  0.001892  0.000725   0.0   \n",
       "\n",
       "       19_y      20_y      21_y      22_y      23_y      24_y  \n",
       "0  0.002246  0.001787  0.003241  0.003036  0.004602  0.009414  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.003095  0.000000  0.015545  0.000000  0.029988  \n",
       "4  0.003100  0.001592  0.004266  0.003174  0.004424  0.009140  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4183180, 65)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2208719064"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Like/Dislike Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_data.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_columns = [c for c in train_data.columns if c not in ['user_id', 'book_id', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_data[x_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_deep = WideDeep(num_classes=1, batch_size=128, lambda_1=0.01, extra_hidden=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 512)          32256       input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 512)          0           dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 128)          65664       dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 128)          0           dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 1)            129         dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 1)            63          input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1)            0           dense_64[0][0]                   \n",
      "                                                                 dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 1)            2           add_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 98,114\n",
      "Trainable params: 98,114\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3346544 samples, validate on 836636 samples\n",
      "Epoch 1/100\n",
      "3346544/3346544 [==============================] - 273s 82us/step - loss: 0.6287 - acc: 0.6894 - val_loss: 0.6201 - val_acc: 0.6895\n",
      "Epoch 2/100\n",
      "3346544/3346544 [==============================] - 291s 87us/step - loss: 0.6200 - acc: 0.6898 - val_loss: 0.6201 - val_acc: 0.6895\n",
      "Epoch 3/100\n",
      "3346544/3346544 [==============================] - 273s 82us/step - loss: 0.6198 - acc: 0.6898 - val_loss: 0.6197 - val_acc: 0.6895\n",
      "Epoch 4/100\n",
      "3346544/3346544 [==============================] - 290s 87us/step - loss: 0.6197 - acc: 0.6898 - val_loss: 0.6197 - val_acc: 0.6895\n",
      "Epoch 5/100\n",
      "3346544/3346544 [==============================] - 290s 87us/step - loss: 0.6196 - acc: 0.6898 - val_loss: 0.6197 - val_acc: 0.6895\n"
     ]
    }
   ],
   "source": [
    "wide_deep.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 512)          32256       input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 512)          0           dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 128)          65664       dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 128)          0           dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 1)            129         dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 1)            63          input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1)            0           dense_69[0][0]                   \n",
      "                                                                 dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 1)            2           add_4[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 98,114\n",
      "Trainable params: 98,114\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3346544 samples, validate on 836636 samples\n",
      "Epoch 1/100\n",
      "3346544/3346544 [==============================] - 275s 82us/step - loss: 0.7643 - acc: 0.6895 - val_loss: 0.5661 - val_acc: 0.6895\n",
      "Epoch 2/100\n",
      "3346544/3346544 [==============================] - 293s 87us/step - loss: 0.5449 - acc: 0.7172 - val_loss: 0.5319 - val_acc: 0.7386\n",
      "Epoch 3/100\n",
      "3346544/3346544 [==============================] - 293s 88us/step - loss: 0.5318 - acc: 0.7386 - val_loss: 0.5300 - val_acc: 0.7399\n",
      "Epoch 4/100\n",
      "3346544/3346544 [==============================] - 292s 87us/step - loss: 0.5281 - acc: 0.7393 - val_loss: 0.5258 - val_acc: 0.7404\n",
      "Epoch 5/100\n",
      "3346544/3346544 [==============================] - 293s 88us/step - loss: 0.5262 - acc: 0.7397 - val_loss: 0.5219 - val_acc: 0.7401\n",
      "Epoch 6/100\n",
      "3346544/3346544 [==============================] - 286s 85us/step - loss: 0.5250 - acc: 0.7399 - val_loss: 0.5216 - val_acc: 0.7406\n",
      "Epoch 7/100\n",
      "3346544/3346544 [==============================] - 294s 88us/step - loss: 0.5240 - acc: 0.7401 - val_loss: 0.5215 - val_acc: 0.7406\n",
      "Epoch 8/100\n",
      "3346544/3346544 [==============================] - 293s 87us/step - loss: 0.5234 - acc: 0.7403 - val_loss: 0.5219 - val_acc: 0.7406\n"
     ]
    }
   ],
   "source": [
    "wide_deep = WideDeep(num_classes=1, batch_size=128, lambda_1=0.1, extra_hidden=False)\n",
    "wide_deep.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_deep.deep.save('models/wide_deep_1_01_128_False.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 512)          32256       input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 512)          0           dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 128)          65664       dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 128)          0           dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 1)            129         dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 1)            63          input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1)            0           dense_74[0][0]                   \n",
      "                                                                 dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 1)            2           add_5[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 98,114\n",
      "Trainable params: 98,114\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3346544 samples, validate on 836636 samples\n",
      "Epoch 1/100\n",
      "3346544/3346544 [==============================] - 156s 46us/step - loss: 0.8276 - acc: 0.6879 - val_loss: 0.6298 - val_acc: 0.6895\n",
      "Epoch 2/100\n",
      "3346544/3346544 [==============================] - 155s 46us/step - loss: 0.6433 - acc: 0.6898 - val_loss: 0.6256 - val_acc: 0.6895\n",
      "Epoch 3/100\n",
      "3346544/3346544 [==============================] - 156s 46us/step - loss: 0.6361 - acc: 0.6898 - val_loss: 0.6216 - val_acc: 0.6895\n",
      "Epoch 4/100\n",
      "3346544/3346544 [==============================] - 155s 46us/step - loss: 0.6330 - acc: 0.6898 - val_loss: 0.6232 - val_acc: 0.6895\n"
     ]
    }
   ],
   "source": [
    "wide_deep = WideDeep(num_classes=1, batch_size=256, lambda_1=0.1, extra_hidden=False)\n",
    "wide_deep.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 512)          32256       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          131328      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          32896       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            129         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            63          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1)            0           dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            2           add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 196,674\n",
      "Trainable params: 196,674\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3346544 samples, validate on 836636 samples\n",
      "Epoch 1/100\n",
      "3346544/3346544 [==============================] - 293s 87us/step - loss: 0.7483 - acc: 0.6889 - val_loss: 0.6231 - val_acc: 0.6895\n",
      "Epoch 2/100\n",
      "3346544/3346544 [==============================] - 308s 92us/step - loss: 0.6277 - acc: 0.6898 - val_loss: 0.6261 - val_acc: 0.6895\n"
     ]
    }
   ],
   "source": [
    "wide_deep = WideDeep(num_classes=1, batch_size=128, lambda_1=0.1, extra_hidden=True)\n",
    "wide_deep.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 512)          32256       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 512)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          65664       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            129         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            63          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1)            0           dense_14[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            2           add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 98,114\n",
      "Trainable params: 98,114\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3346544 samples, validate on 836636 samples\n",
      "Epoch 1/100\n",
      "3346544/3346544 [==============================] - 270s 81us/step - loss: 0.8982 - acc: 0.7352 - val_loss: 0.5612 - val_acc: 0.7392\n",
      "Epoch 2/100\n",
      "3346544/3346544 [==============================] - 287s 86us/step - loss: 0.5622 - acc: 0.7388 - val_loss: 0.5460 - val_acc: 0.7399\n",
      "Epoch 3/100\n",
      "3346544/3346544 [==============================] - 287s 86us/step - loss: 0.5502 - acc: 0.7395 - val_loss: 0.5486 - val_acc: 0.7402\n"
     ]
    }
   ],
   "source": [
    "wide_deep = WideDeep(num_classes=1, batch_size=128, lambda_1=0.5, extra_hidden=False)\n",
    "wide_deep.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_deep.deep.save('models/wide_deep_1_5_128_False.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 512)          32256       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 512)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          65664       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128)          0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            129         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            63          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1)            0           dense_19[0][0]                   \n",
      "                                                                 dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1)            2           add_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 98,114\n",
      "Trainable params: 98,114\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3346544 samples, validate on 836636 samples\n",
      "Epoch 1/100\n",
      "3346544/3346544 [==============================] - 525s 157us/step - loss: 0.7835 - acc: 0.6893 - val_loss: 0.6316 - val_acc: 0.6895\n",
      "Epoch 2/100\n",
      "3346544/3346544 [==============================] - 558s 167us/step - loss: 0.6324 - acc: 0.6898 - val_loss: 0.6231 - val_acc: 0.6895\n",
      "Epoch 3/100\n",
      "3346544/3346544 [==============================] - 542s 162us/step - loss: 0.6291 - acc: 0.6898 - val_loss: 0.6247 - val_acc: 0.6895\n"
     ]
    }
   ],
   "source": [
    "wide_deep = WideDeep(num_classes=1, batch_size=64, lambda_1=0.5, extra_hidden=False)\n",
    "wide_deep.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-5 Rating Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_5 = train_data['rating']\n",
    "y_train_5 = to_categorical(y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1496995\n",
       "5    1388429\n",
       "3     959931\n",
       "2     250846\n",
       "1      86979\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['rating'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4183180, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_5 = train_data.apply(lambda x: x['rating'] - 1, axis=1)\n",
    "y_train_5 = to_categorical(y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4183180, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 512)          32256       input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 512)          0           dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 128)          65664       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 128)          0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 5)            645         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 1)            63          input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 6)            0           dense_48[0][0]                   \n",
      "                                                                 dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 5)            35          concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 98,663\n",
      "Trainable params: 98,663\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3346544 samples, validate on 836636 samples\n",
      "Epoch 1/100\n",
      "3346544/3346544 [==============================] - 265s 79us/step - loss: 1.3937 - acc: 0.4768 - val_loss: 1.1548 - val_acc: 0.4854\n",
      "Epoch 2/100\n",
      "3346544/3346544 [==============================] - 285s 85us/step - loss: 1.1618 - acc: 0.4839 - val_loss: 1.1482 - val_acc: 0.4863\n",
      "Epoch 3/100\n",
      "3346544/3346544 [==============================] - 280s 84us/step - loss: 1.1562 - acc: 0.4849 - val_loss: 1.1480 - val_acc: 0.4870\n",
      "Epoch 4/100\n",
      "3346544/3346544 [==============================] - 284s 85us/step - loss: 1.1536 - acc: 0.4854 - val_loss: 1.1487 - val_acc: 0.4867\n"
     ]
    }
   ],
   "source": [
    "wide_deep = WideDeep(num_classes=5, batch_size=128, lambda_1=0.1, extra_hidden=False)\n",
    "wide_deep.fit(x_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_deep.deep.save('models/wide_deep_5_1_128_False.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 512)          32256       input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 512)          0           dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 128)          65664       dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 128)          0           dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 5)            645         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 1)            63          input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 6)            0           dense_53[0][0]                   \n",
      "                                                                 dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 5)            35          concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 98,663\n",
      "Trainable params: 98,663\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3346544 samples, validate on 836636 samples\n",
      "Epoch 1/100\n",
      "3346544/3346544 [==============================] - 285s 85us/step - loss: 1.7323 - acc: 0.4723 - val_loss: 1.1653 - val_acc: 0.4854\n",
      "Epoch 2/100\n",
      "3346544/3346544 [==============================] - 286s 85us/step - loss: 1.1904 - acc: 0.4833 - val_loss: 1.1709 - val_acc: 0.4862\n"
     ]
    }
   ],
   "source": [
    "wide_deep = WideDeep(num_classes=5, batch_size=128, lambda_1=0.5, extra_hidden=False)\n",
    "wide_deep.fit(x_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 512)          32256       input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 512)          0           dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 256)          131328      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 256)          0           dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 128)          32896       dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 128)          0           dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 5)            645         dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 1)            63          input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 6)            0           dense_59[0][0]                   \n",
      "                                                                 dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 5)            35          concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,223\n",
      "Trainable params: 197,223\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3346544 samples, validate on 836636 samples\n",
      "Epoch 1/100\n",
      "3346544/3346544 [==============================] - 293s 88us/step - loss: 1.4770 - acc: 0.3568 - val_loss: 1.3432 - val_acc: 0.3577\n",
      "Epoch 2/100\n",
      "3346544/3346544 [==============================] - 311s 93us/step - loss: 1.3326 - acc: 0.3579 - val_loss: 1.3261 - val_acc: 0.3577\n",
      "Epoch 3/100\n",
      "3346544/3346544 [==============================] - 311s 93us/step - loss: 1.3276 - acc: 0.3579 - val_loss: 1.3233 - val_acc: 0.3577\n",
      "Epoch 4/100\n",
      "3346544/3346544 [==============================] - 311s 93us/step - loss: 1.3262 - acc: 0.3579 - val_loss: 1.3244 - val_acc: 0.3577\n"
     ]
    }
   ],
   "source": [
    "wide_deep = WideDeep(num_classes=5, batch_size=128, lambda_1=0.1, extra_hidden=True)\n",
    "wide_deep.fit(x_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          32256       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5)            645         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            63          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6)            0           dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5)            35          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,223\n",
      "Trainable params: 197,223\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3346544 samples, validate on 836636 samples\n",
      "Epoch 1/100\n",
      "3346544/3346544 [==============================] - 164s 49us/step - loss: 1.6954 - acc: 0.4739 - val_loss: 1.1718 - val_acc: 0.4841\n",
      "Epoch 2/100\n",
      "3346544/3346544 [==============================] - 164s 49us/step - loss: 1.1839 - acc: 0.4836 - val_loss: 1.1532 - val_acc: 0.4862\n",
      "Epoch 3/100\n",
      "3346544/3346544 [==============================] - 163s 49us/step - loss: 1.1693 - acc: 0.4847 - val_loss: 1.1521 - val_acc: 0.4868\n",
      "Epoch 4/100\n",
      "3346544/3346544 [==============================] - 164s 49us/step - loss: 1.1636 - acc: 0.4855 - val_loss: 1.1543 - val_acc: 0.4874\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTIdYIjHGGNMhlkiMMcZ0yP8HZFErBMDNmfQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe501700940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHO9srQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe4fb701ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wide_deep = WideDeep(num_classes=5, batch_size=256, lambda_1=0.1, extra_hidden=True)\n",
    "wide_deep.fit(x_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          32256       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          131328      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          32896       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 5)            645         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            63          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6)            0           dense_10[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 5)            35          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 197,223\n",
      "Trainable params: 197,223\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3346544 samples, validate on 836636 samples\n",
      "Epoch 1/20\n",
      "3346544/3346544 [==============================] - 163s 49us/step - loss: 1.6030 - acc: 0.3574 - val_loss: 1.3845 - val_acc: 0.3577\n",
      "Epoch 2/20\n",
      "3346544/3346544 [==============================] - 165s 49us/step - loss: 1.3623 - acc: 0.3579 - val_loss: 1.3300 - val_acc: 0.3577\n",
      "Epoch 3/20\n",
      "3346544/3346544 [==============================] - 163s 49us/step - loss: 1.3412 - acc: 0.3579 - val_loss: 1.3278 - val_acc: 0.3577\n",
      "Epoch 4/20\n",
      "3346544/3346544 [==============================] - 165s 49us/step - loss: 1.3362 - acc: 0.3579 - val_loss: 1.3260 - val_acc: 0.3577\n",
      "Epoch 5/20\n",
      "3346544/3346544 [==============================] - 163s 49us/step - loss: 1.3337 - acc: 0.3579 - val_loss: 1.3253 - val_acc: 0.3577\n",
      "Epoch 6/20\n",
      "3346544/3346544 [==============================] - 163s 49us/step - loss: 1.3322 - acc: 0.3579 - val_loss: 1.3242 - val_acc: 0.3577\n",
      "Epoch 7/20\n",
      "3346544/3346544 [==============================] - 164s 49us/step - loss: 1.3311 - acc: 0.3579 - val_loss: 1.3233 - val_acc: 0.3577\n",
      "Epoch 8/20\n",
      "3346544/3346544 [==============================] - 165s 49us/step - loss: 1.3302 - acc: 0.3579 - val_loss: 1.3239 - val_acc: 0.3577\n",
      "Epoch 9/20\n",
      "3346544/3346544 [==============================] - 164s 49us/step - loss: 1.3296 - acc: 0.3579 - val_loss: 1.3239 - val_acc: 0.3577\n",
      "Epoch 10/20\n",
      "3346544/3346544 [==============================] - 164s 49us/step - loss: 1.3291 - acc: 0.3579 - val_loss: 1.3246 - val_acc: 0.3577\n",
      "Epoch 11/20\n",
      "3346544/3346544 [==============================] - 165s 49us/step - loss: 1.3286 - acc: 0.3579 - val_loss: 1.3235 - val_acc: 0.3577\n",
      "Epoch 12/20\n",
      "3346544/3346544 [==============================] - 163s 49us/step - loss: 1.3283 - acc: 0.3579 - val_loss: 1.3234 - val_acc: 0.3577\n",
      "Epoch 13/20\n",
      "3346544/3346544 [==============================] - 165s 49us/step - loss: 1.3280 - acc: 0.3579 - val_loss: 1.3238 - val_acc: 0.3577\n",
      "Epoch 14/20\n",
      "3346544/3346544 [==============================] - 159s 47us/step - loss: 1.3277 - acc: 0.3579 - val_loss: 1.3238 - val_acc: 0.3577\n",
      "Epoch 15/20\n",
      "3346544/3346544 [==============================] - 164s 49us/step - loss: 1.3274 - acc: 0.3579 - val_loss: 1.3263 - val_acc: 0.3577\n",
      "Epoch 16/20\n",
      "3346544/3346544 [==============================] - 165s 49us/step - loss: 1.3272 - acc: 0.3579 - val_loss: 1.3229 - val_acc: 0.3577\n",
      "Epoch 17/20\n",
      "3346544/3346544 [==============================] - 157s 47us/step - loss: 1.3270 - acc: 0.3579 - val_loss: 1.3243 - val_acc: 0.3577\n",
      "Epoch 18/20\n",
      "3346544/3346544 [==============================] - 165s 49us/step - loss: 1.3268 - acc: 0.3579 - val_loss: 1.3228 - val_acc: 0.3577\n",
      "Epoch 19/20\n",
      "3346544/3346544 [==============================] - 165s 49us/step - loss: 1.3267 - acc: 0.3579 - val_loss: 1.3229 - val_acc: 0.3577\n",
      "Epoch 20/20\n",
      "3346544/3346544 [==============================] - 159s 48us/step - loss: 1.3265 - acc: 0.3579 - val_loss: 1.3230 - val_acc: 0.3577\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njJmZ5cIJxszMcuEEY2Zmufj/ZkNFBYJCtKEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe4fae1e1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhISRQYIiJSEgWGiIiURIEhIiIl+f9qCa40Irk2wwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe4fb7dbc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wide_deep = WideDeep(num_classes=5, batch_size=256, lambda_1=0.1, extra_hidden=True, epochs=20)\n",
    "wide_deep.fit(x_train, y_train_5, early_stopping=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ratings = pd.read_csv('data/test_ratings_set.csv')\n",
    "book_features = pd.read_csv('data/books_with_latent_features.csv')\n",
    "user_features = pd.read_csv('data/user_features_final.csv')\n",
    "test_data = test_ratings.merge(user_features, how='left', on='user_id')\n",
    "test_data = test_data.merge(book_features, how='left', on='book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_model = load_model('models/wide_deep_1_01_128_False.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_binary = test_ratings.apply(lambda x: 1 if x['rating'] > 3 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = test_data.drop(['user_id', 'book_id', 'rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_binary = np.asarray(y_binary)\n",
    "x_test = np.asarray(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792792/1792792 [==============================] - 106s 59us/step\n"
     ]
    }
   ],
   "source": [
    "evaluate = binary_model.evaluate(x_test, y_binary, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5257303538434966, 0.7365238131364246]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792792/1792792 [==============================] - 154s 86us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = binary_model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73439026],\n",
       "       [0.8443906 ],\n",
       "       [0.9035205 ],\n",
       "       ...,\n",
       "       [0.8843127 ],\n",
       "       [0.7838348 ],\n",
       "       [0.352266  ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1792792, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_formated = np.rint(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation_data = test_data[['user_id', 'book_id', 'rating']].copy()\n",
    "evaluation_data['pred_proba'] = predictions\n",
    "evaluation_data['prediction'] = predictions_formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation_data['binary_rating'] = y_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfm, p, r = ev.replay_binary_results(evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 204889  351503]\n",
      " [ 120855 1115545]]\n"
     ]
    }
   ],
   "source": [
    "print(cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7604011593349366 0.9022525072791977\n"
     ]
    }
   ],
   "source": [
    "print(p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation_data.to_csv('data/backups/wd_eval1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>prediction</th>\n",
       "      <th>binary_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18218</td>\n",
       "      <td>920</td>\n",
       "      <td>3</td>\n",
       "      <td>0.734390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34091</td>\n",
       "      <td>967</td>\n",
       "      <td>4</td>\n",
       "      <td>0.844391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41266</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>0.903520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47336</td>\n",
       "      <td>760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.643581</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20893</td>\n",
       "      <td>453</td>\n",
       "      <td>3</td>\n",
       "      <td>0.621612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating  pred_proba  prediction  binary_rating\n",
       "0    18218      920       3    0.734390         1.0              0\n",
       "1    34091      967       4    0.844391         1.0              1\n",
       "2    41266       71       5    0.903520         1.0              1\n",
       "3    47336      760       5    0.643581         1.0              1\n",
       "4    20893      453       3    0.621612         1.0              0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_data = pd.read_csv('data/backups/wd_eval1.csv')\n",
    "evaluation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily-air13/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py:526: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 users evaluated\n",
      "1000 users evaluated\n",
      "1500 users evaluated\n",
      "2000 users evaluated\n",
      "2500 users evaluated\n",
      "3000 users evaluated\n",
      "3500 users evaluated\n",
      "4000 users evaluated\n",
      "4500 users evaluated\n",
      "5000 users evaluated\n",
      "5500 users evaluated\n",
      "6000 users evaluated\n",
      "6500 users evaluated\n",
      "7000 users evaluated\n",
      "7500 users evaluated\n",
      "8000 users evaluated\n",
      "8500 users evaluated\n",
      "9000 users evaluated\n",
      "9500 users evaluated\n",
      "10000 users evaluated\n",
      "10500 users evaluated\n",
      "11000 users evaluated\n",
      "11500 users evaluated\n",
      "12000 users evaluated\n",
      "12500 users evaluated\n",
      "13000 users evaluated\n",
      "13500 users evaluated\n",
      "14000 users evaluated\n",
      "14500 users evaluated\n",
      "15000 users evaluated\n",
      "15500 users evaluated\n",
      "16000 users evaluated\n",
      "16500 users evaluated\n",
      "17000 users evaluated\n",
      "17500 users evaluated\n",
      "18000 users evaluated\n",
      "18500 users evaluated\n",
      "19000 users evaluated\n",
      "19500 users evaluated\n",
      "20000 users evaluated\n",
      "20500 users evaluated\n",
      "21000 users evaluated\n",
      "21500 users evaluated\n",
      "22000 users evaluated\n",
      "22500 users evaluated\n",
      "23000 users evaluated\n",
      "23500 users evaluated\n",
      "24000 users evaluated\n",
      "24500 users evaluated\n",
      "25000 users evaluated\n",
      "25500 users evaluated\n",
      "26000 users evaluated\n",
      "26500 users evaluated\n",
      "27000 users evaluated\n",
      "27500 users evaluated\n",
      "28000 users evaluated\n",
      "28500 users evaluated\n",
      "29000 users evaluated\n",
      "29500 users evaluated\n",
      "30000 users evaluated\n",
      "30500 users evaluated\n",
      "31000 users evaluated\n",
      "31500 users evaluated\n",
      "32000 users evaluated\n",
      "32500 users evaluated\n",
      "33000 users evaluated\n",
      "33500 users evaluated\n",
      "34000 users evaluated\n",
      "34500 users evaluated\n",
      "35000 users evaluated\n",
      "35500 users evaluated\n",
      "36000 users evaluated\n",
      "36500 users evaluated\n",
      "37000 users evaluated\n",
      "37500 users evaluated\n",
      "38000 users evaluated\n",
      "38500 users evaluated\n",
      "39000 users evaluated\n",
      "39500 users evaluated\n",
      "40000 users evaluated\n",
      "40500 users evaluated\n",
      "41000 users evaluated\n",
      "41500 users evaluated\n",
      "42000 users evaluated\n",
      "42500 users evaluated\n",
      "43000 users evaluated\n",
      "43500 users evaluated\n",
      "44000 users evaluated\n",
      "44500 users evaluated\n",
      "45000 users evaluated\n",
      "45500 users evaluated\n",
      "46000 users evaluated\n",
      "46500 users evaluated\n",
      "47000 users evaluated\n",
      "47500 users evaluated\n",
      "48000 users evaluated\n",
      "48500 users evaluated\n",
      "49000 users evaluated\n",
      "49500 users evaluated\n",
      "50000 users evaluated\n",
      "50500 users evaluated\n",
      "51000 users evaluated\n",
      "51500 users evaluated\n",
      "52000 users evaluated\n",
      "52500 users evaluated\n",
      "53000 users evaluated\n"
     ]
    }
   ],
   "source": [
    "mAP, n = top_10_binary_results(evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5929090723776069 0\n"
     ]
    }
   ],
   "source": [
    "print(mAP, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_5 = test_data.apply(lambda x: x['rating'] - 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_5 = to_categorical(np.asarray(y_test_5))\n",
    "x_test = np.asarray(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/voldemort/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "star5_model = load_model('models/wide_deep_5_1_128_False.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792792/1792792 [==============================] - 28s 15us/step\n"
     ]
    }
   ],
   "source": [
    "evaluation = star5_model.evaluate(x_test, y_test_5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1565596667748237, 0.48103126296873167]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792792/1792792 [==============================] - 17s 10us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = star5_model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1792792, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01657924, 0.04514957, 0.20334531, 0.4058831 , 0.32904282],\n",
       "       [0.00650869, 0.02216436, 0.14680913, 0.4009271 , 0.42359075],\n",
       "       [0.00446666, 0.01040739, 0.06184202, 0.23993082, 0.6833531 ],\n",
       "       ...,\n",
       "       [0.00487425, 0.01513677, 0.10773239, 0.36219245, 0.5100642 ],\n",
       "       [0.00252846, 0.0192401 , 0.22556204, 0.53188074, 0.2207887 ],\n",
       "       [0.05092024, 0.16127434, 0.41674414, 0.29408756, 0.07697359]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 4, ..., 4, 3, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_formated = np.argmax(predictions, axis=1)\n",
    "predictions_formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 5, ..., 5, 4, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_formated = predictions_formated + 1\n",
    "predictions_formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation_data = test_data[['user_id', 'book_id', 'rating']].copy()\n",
    "evaluation_data['pred_proba'] = predictions[:,4]\n",
    "evaluation_data['prediction'] = predictions_formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfm, p, r = ev.replay_5star_results(evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1891,    438,  15715,  14629,   4487],\n",
       "       [   748,    736,  48225,  48346,  10314],\n",
       "       [   456,    509, 129521, 224463,  55914],\n",
       "       [   178,    228,  89920, 372830, 178700],\n",
       "       [   131,     95,  25814, 211093, 357411]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4782048316600647 0.4810312629685987\n"
     ]
    }
   ],
   "source": [
    "print(p, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voldemort/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py:526: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users evaluated\n",
      "500 users evaluated\n",
      "1000 users evaluated\n",
      "1500 users evaluated\n",
      "2000 users evaluated\n",
      "2500 users evaluated\n",
      "3000 users evaluated\n",
      "3500 users evaluated\n",
      "4000 users evaluated\n",
      "4500 users evaluated\n",
      "5000 users evaluated\n",
      "5500 users evaluated\n",
      "6000 users evaluated\n",
      "6500 users evaluated\n",
      "7000 users evaluated\n",
      "7500 users evaluated\n",
      "8000 users evaluated\n",
      "8500 users evaluated\n",
      "9000 users evaluated\n",
      "9500 users evaluated\n",
      "10000 users evaluated\n",
      "10500 users evaluated\n",
      "11000 users evaluated\n",
      "11500 users evaluated\n",
      "12000 users evaluated\n",
      "12500 users evaluated\n",
      "13000 users evaluated\n",
      "13500 users evaluated\n",
      "14000 users evaluated\n",
      "14500 users evaluated\n",
      "15000 users evaluated\n",
      "15500 users evaluated\n",
      "16000 users evaluated\n",
      "16500 users evaluated\n",
      "17000 users evaluated\n",
      "17500 users evaluated\n",
      "18000 users evaluated\n",
      "18500 users evaluated\n",
      "19000 users evaluated\n",
      "19500 users evaluated\n",
      "20000 users evaluated\n",
      "20500 users evaluated\n",
      "21000 users evaluated\n",
      "21500 users evaluated\n",
      "22000 users evaluated\n",
      "22500 users evaluated\n",
      "23000 users evaluated\n",
      "23500 users evaluated\n",
      "24000 users evaluated\n",
      "24500 users evaluated\n",
      "25000 users evaluated\n",
      "25500 users evaluated\n",
      "26000 users evaluated\n",
      "26500 users evaluated\n",
      "27000 users evaluated\n",
      "27500 users evaluated\n",
      "28000 users evaluated\n",
      "28500 users evaluated\n",
      "29000 users evaluated\n",
      "29500 users evaluated\n",
      "30000 users evaluated\n",
      "30500 users evaluated\n",
      "31000 users evaluated\n",
      "31500 users evaluated\n",
      "32000 users evaluated\n",
      "32500 users evaluated\n",
      "33000 users evaluated\n",
      "33500 users evaluated\n",
      "34000 users evaluated\n",
      "34500 users evaluated\n",
      "35000 users evaluated\n",
      "35500 users evaluated\n",
      "36000 users evaluated\n",
      "36500 users evaluated\n",
      "37000 users evaluated\n",
      "37500 users evaluated\n",
      "38000 users evaluated\n",
      "38500 users evaluated\n",
      "39000 users evaluated\n",
      "39500 users evaluated\n",
      "40000 users evaluated\n",
      "40500 users evaluated\n",
      "41000 users evaluated\n",
      "41500 users evaluated\n",
      "42000 users evaluated\n",
      "42500 users evaluated\n",
      "43000 users evaluated\n",
      "43500 users evaluated\n",
      "44000 users evaluated\n",
      "44500 users evaluated\n",
      "45000 users evaluated\n",
      "45500 users evaluated\n",
      "46000 users evaluated\n",
      "46500 users evaluated\n",
      "47000 users evaluated\n",
      "47500 users evaluated\n",
      "48000 users evaluated\n",
      "48500 users evaluated\n",
      "49000 users evaluated\n",
      "49500 users evaluated\n",
      "50000 users evaluated\n",
      "50500 users evaluated\n",
      "51000 users evaluated\n",
      "51500 users evaluated\n",
      "52000 users evaluated\n",
      "52500 users evaluated\n",
      "53000 users evaluated\n"
     ]
    }
   ],
   "source": [
    "aps, mAP, binary_mAP, binary_aps, skipped = ev.top_10_5star_results(evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07100897147746114 0.6061237993002462\n"
     ]
    }
   ],
   "source": [
    "print(mAP, binary_mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation_data.to_csv('data/backups/wd_eval5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18218</td>\n",
       "      <td>920</td>\n",
       "      <td>3</td>\n",
       "      <td>0.329043</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34091</td>\n",
       "      <td>967</td>\n",
       "      <td>4</td>\n",
       "      <td>0.423591</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41266</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>0.683353</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47336</td>\n",
       "      <td>760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.163343</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20893</td>\n",
       "      <td>453</td>\n",
       "      <td>3</td>\n",
       "      <td>0.215606</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating  pred_proba  prediction\n",
       "0    18218      920       3    0.329043           4\n",
       "1    34091      967       4    0.423591           5\n",
       "2    41266       71       5    0.683353           5\n",
       "3    47336      760       5    0.163343           4\n",
       "4    20893      453       3    0.215606           4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_data = pd.read_csv('data/backups/wd_eval5.csv')\n",
    "evaluation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
